{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JRDBデータを使用したランキング学習モデル\n",
    "\n",
    "年度パックNPZファイルからデータを読み込み、LambdaRankモデルを学習します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インポート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ インポート成功: CacheManager, TrainingDataProcessor\n",
      "✓ インデントエラーは修正されました\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# プロジェクトルート（apps/prediction/）をパスに追加\n",
    "project_root = Path().resolve().parent  # notebooks/ -> apps/prediction/\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# autoreloadを先に設定（これにより、以降のインポートが自動リロード対象になる）\n",
    "# %reload_ext autoreload  # nbconvert実行時はコメントアウト\n",
    "# %autoreload 2\n",
    "\n",
    "# 既にインポート済みのモジュールを明示的にリロード（初回実行時）\n",
    "# training_data_processor配下のサブモジュールも含めてリロード\n",
    "# 注意: サブモジュールを先にリロードしてから、親モジュールをリロードする必要がある\n",
    "submodules_to_reload = [\n",
    "    'src.training_data_processor.horse_statistics',\n",
    "    'src.training_data_processor.jockey_statistics',\n",
    "    'src.training_data_processor.trainer_statistics',\n",
    "    'src.training_data_processor.statistical_feature_calculator',\n",
    "    'src.training_data_processor.cache_manager',\n",
    "    'src.training_data_processor.training_data_processor',\n",
    "    'src.training_data_processor.previous_race_extractor',\n",
    "    'src.training_data_processor.jrdb_processor',\n",
    "]\n",
    "\n",
    "# サブモジュールを先にリロード\n",
    "for module_name in submodules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "\n",
    "# 親モジュールをリロード\n",
    "parent_modules_to_reload = [\n",
    "    'src.data_loader',\n",
    "    'src.rank_predictor',\n",
    "    'src.features',\n",
    "    'src.feature_converter',\n",
    "    'src.training_data_processor',\n",
    "]\n",
    "\n",
    "for module_name in parent_modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.training_data_processor import CacheManager, TrainingDataProcessor\n",
    "from src.rank_predictor import RankPredictor\n",
    "from src.features import Features\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ インポート成功: CacheManager, TrainingDataProcessor\")\n",
    "print(\"✓ インデントエラーは修正されました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH: /Users/soichiro/Dev/umayomi/apps/prediction/notebooks/data\n",
      "見つかったNPZファイル: 10件\n",
      "  - jrdb_npz_SEC_2024.npz\n",
      "  - jrdb_npz_UKC_2024.npz\n",
      "  - jrdb_npz_KYH_2024.npz\n",
      "  - jrdb_npz_KYI_2024.npz\n",
      "  - jrdb_npz_SED_2024.npz\n"
     ]
    }
   ],
   "source": [
    "# NPZファイルが格納されているベースパス\n",
    "# ノートブックと同じディレクトリのdataフォルダにNPZファイルを配置\n",
    "BASE_PATH = Path('./data')  # apps/prediction/notebooks/data\n",
    "\n",
    "# 使用するデータタイプ\n",
    "# レース開始時点で利用可能なデータのみを含める\n",
    "# オッズデータ（OZ, OW, OU, OT, OV）と払戻データ（HJC, HJB）は除外\n",
    "DATA_TYPES = [\n",
    "    'BAC',  # 番組データ（レース条件・出走馬一覧）\n",
    "    'KYI',  # 競走馬データ（牧場先情報付き・最も詳細）\n",
    "    'SED',  # 成績速報データ（過去の成績・前走データ抽出に使用）\n",
    "    'UKC',  # 馬基本データ（血統登録番号・性別・生年月日・血統情報）\n",
    "    'TYB',  # 直前情報データ（出走直前の馬の状態・当日予想に最重要）\n",
    "    # 以下は年度パックがないため、現時点では除外\n",
    "    # 'KKA',  # 競走馬拡張データ（KY系の詳細情報・年度パックなし・予測モデルでは直接使用されていない）\n",
    "    # 'JOA',  # 情報データ（詳細情報による予想精度向上・年度パックなし・予測モデルでは直接使用されていない）\n",
    "    # マスターデータ（使用しない）\n",
    "    # 'KZA',  # 騎手データ（全騎手分・勝率・連対率）\n",
    "    # 'CZA',  # 調教師データ（全調教師分・勝率・連対率）\n",
    "    # 注意: マスターデータには最新の統計情報が含まれるため、未来の情報が混入する可能性がある\n",
    "    # 代わりに、SEDデータから時系列で統計量を計算（add_statistical_features）を使用\n",
    "]\n",
    "\n",
    "# 使用する年度\n",
    "YEARS = [2024]  # 必要に応じて複数年度を指定\n",
    "\n",
    "# モデル保存パス（日時ベース）\n",
    "from datetime import datetime\n",
    "model_timestamp = datetime.now().strftime('%Y%m%d%H%M')\n",
    "MODEL_PATH = Path(f'../models/rank_model_{model_timestamp}_v1.txt')\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ファイル名の確認（デバッグ用）\n",
    "print(f\"BASE_PATH: {BASE_PATH.absolute()}\")\n",
    "if BASE_PATH.exists():\n",
    "    npz_files = list(BASE_PATH.glob('*.npz'))\n",
    "    print(f\"見つかったNPZファイル: {len(npz_files)}件\")\n",
    "    for f in npz_files[:5]:  # 最初の5件を表示\n",
    "        print(f\"  - {f.name}\")\n",
    "else:\n",
    "    print(f\"警告: {BASE_PATH} が存在しません\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込みと前処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ読み込みと前処理を開始します...\n",
      "キャッシュが見つかりません。データを作成します...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "データタイプ読み込み: 100%|██████████| 5/5 [00:00<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前走データ抽出中（並列処理: 11コア、11786頭）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done 7498 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=11)]: Done 11786 out of 11786 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "馬の統計量を計算中...\n",
      "  target_dfをソート中... (target_df: 522,906件)\n",
      "  ソート完了: 0.98秒\n",
      "  horse統計量計算: データソート中... (stats: 54,953件, target: 522,906件)\n",
      "  ソート完了: 0.01秒\n",
      "  累積統計量計算中... (グループ数: 16,536)\n",
      "  累積統計量計算完了: 0.02秒\n",
      "  過去統計量マージ実行中...\n",
      "  グループ処理中: 11,786グループ\n",
      "  並列処理実行中: 11コア、11,786グループ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  horseグループ処理: 100%|██████████| 11.8k/11.8k [00:15<00:00, 758groups/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataFrame結合中... (11786個のDataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  結合完了: 0.23秒\n",
      "  マージ完了: 16.35秒\n",
      "  統計量計算中...\n",
      "  統計量計算完了: 0.00秒\n",
      "  インデックス復元中... (target: 522,906件)\n",
      "    merge実行中... (merged: 522,906件)\n",
      "  インデックス復元完了: 0.07秒\n",
      "  target_dfにhorse統計量を結合中... (target_df: 522,906件, horse_stats: 522,906件)\n",
      "    キー一致確認中...\n",
      "    horse_statsを列結合中...\n",
      "    列結合完了: 0.27秒 (結果: 522,906件, カラム数: 363)\n",
      "  結合完了: 0.31秒\n",
      "  インデックス復元中... (target_original_index: 522,906件, target_df_merged: 522,906件)\n",
      "      target_index_df作成中...\n",
      "      → target_index_df作成完了 (522,906件)\n",
      "      target_index_dfとtarget_df_mergedをmerge実行中...\n",
      "        → merge処理開始...\n",
      "        → merge処理終了 (結果: 522,906件)\n",
      "      merge後のカラム削除中... (現在のカラム数: 363)\n",
      "      → カラム削除完了 (カラム数: 362)\n",
      "      インデックス設定中...\n",
      "      → インデックス設定完了\n",
      "    インデックス復元完了: 1.29秒 (最終結果: 522,906件, カラム数: 362)\n",
      "騎手の統計量を計算中...\n",
      "  target_dfをソート中... (target_df: 522,906件)\n",
      "  ソート完了: 0.87秒\n",
      "  jockey統計量計算: データ準備中... (stats: 54,953件, target: 522,906件)\n",
      "  データ準備完了: 0.01秒\n",
      "  全体ソート中... (stats: 54,953件)\n",
      "  ソート完了: 0.00秒\n",
      "  累積統計量計算中... (グループ数: 464)\n",
      "  累積統計量計算完了: 0.00秒\n",
      "  過去統計量マージ実行中...\n",
      "  グループ処理中: 200グループ\n",
      "  並列処理実行中: 11コア、200グループ\n",
      "  batch_size: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichiro/Dev/umayomi/apps/prediction/src/training_data_processor/jockey_statistics.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_sorted['_original_index'] = target_df.index.values\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/src/training_data_processor/jockey_statistics.py:341: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_sorted['_original_index'] = target_df.index.values\n",
      "  jockeyグループ処理:   0%|          | 0.00/200 [00:00<?, ?groups/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      → Parallel処理開始...\n",
      "      → Parallel処理完了 (200件の結果)\n",
      "      → 結果をresult_dfsに追加中...\n",
      "      → 結果追加完了 (200個のDataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jockeyグループ処理: 100%|██████████| 200/200 [00:00<00:00, 2.11kgroups/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataFrame結合中... (200個のDataFrame)\n",
      "    → pd.concat実行中... (合計: 522,906件)\n",
      "    → pd.concat完了 (結果: 522,906件, カラム数: 7)\n",
      "  結合完了: 0.01秒\n",
      "  マージ完了: 0.16秒\n",
      "  統計量計算中... (merged: 522,906件)\n",
      "    → win_rate計算中...\n",
      "    → place_rate計算中...\n",
      "    → avg_rank計算中...\n",
      "    → race_count計算中...\n",
      "    → 統計量計算完了\n",
      "  統計量計算完了: 0.01秒\n",
      "  インデックス復元中... (target: 522,906件, merged: 522,906件)\n",
      "    target_index_df作成中... (target_original_index: 522,906件)\n",
      "    → target_index_df作成完了 (522,906件)\n",
      "    target_index_dfとmergedをmerge実行中... (target_index_df: 522,906件, merged: 522,906件, mergedカラム数: 11)\n",
      "      → merge処理開始...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      → merge処理終了\n",
      "    merge完了: 0.04秒 (結果: 522,906件, カラム数: 11)\n",
      "    _original_indexカラム削除中...\n",
      "    → カラム削除完了 (カラム数: 10)\n",
      "    インデックス設定中...\n",
      "    → インデックス設定完了\n",
      "    必要なカラムのみ選択中... (現在のカラム数: 10)\n",
      "    → カラム選択完了 (カラム数: 6)\n",
      "  インデックス復元完了: 0.06秒 (最終結果: 522,906件, カラム数: 6)\n",
      "  jockey直近レース抽出: データ準備中...\n",
      "  データ準備完了: 0.00秒\n",
      "  groupby→ソート→未来データ削除→結合実行中...\n",
      "  グループ化中... (stats: 54,953件, target: 522,906件)\n",
      "  グループ化完了: 0.00秒\n",
      "  グループ処理中: 200グループ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soichiro/Dev/umayomi/apps/prediction/src/training_data_processor/jockey_statistics.py:521: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_df_subset['_original_index'] = target_df.index.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  並列処理実行中: 11コア、200グループ\n",
      "  batch_size: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jockey直近レース抽出:   0%|          | 0.00/200 [00:00<?, ?groups/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      → Parallel処理開始...\n",
      "      → Parallel処理完了 (200件の結果)\n",
      "      → 結果をresult_dfsに追加中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jockey直近レース抽出:   0%|          | 1.00/200 [00:00<01:15, 2.63groups/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      → 結果追加完了 (200個のDataFrame)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jockey直近レース抽出: 100%|██████████| 200/200 [00:00<00:00, 524groups/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  グループ処理完了: 0.47秒\n",
      "  DataFrame結合中... (200個のDataFrame)\n",
      "    → pd.concat実行中... (合計: 522,906件)\n",
      "    → pd.concat完了 (結果: 522,906件, カラム数: 24)\n",
      "  結合完了: 0.02秒 (合計: 0.49秒)\n",
      "  インデックス復元中... (target: 522,906件, result_df: 522,906件)\n",
      "    target_index_df作成中... (target_original_index: 522,906件)\n",
      "    → target_index_df作成完了 (522,906件)\n",
      "    target_index_dfとresult_dfをmerge実行中... (target_index_df: 522,906件, result_df: 522,906件, result_dfカラム数: 24)\n",
      "      → merge処理開始...\n",
      "      → merge処理終了\n",
      "    merge完了: 0.06秒 (結果: 522,906件, カラム数: 24)\n",
      "    _original_indexカラム削除中...\n",
      "    → カラム削除完了 (カラム数: 23)\n",
      "    インデックス設定中...\n",
      "    → インデックス設定完了\n",
      "  インデックス復元完了: 0.07秒 (最終結果: 522,906件, カラム数: 23)\n",
      "  target_dfにjockey統計量と直近レースを結合中... (target_df: 522,906件, jockey_stats: 522,906件, jockey_recent_races: 522,906件)\n",
      "    [ステップ1/2] キー一致確認中...\n",
      "    [ステップ1/2] jockey_statsを列結合中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [ステップ1/2] 列結合完了: 0.22秒 (結果: 522,906件, カラム数: 367)\n",
      "    [ステップ2/2] キー一致確認中...\n",
      "    [ステップ2/2] jockey_recent_racesを列結合中...\n",
      "    [ステップ2/2] 列結合完了: 0.01秒 (結果: 522,906件, カラム数: 388)\n",
      "  結合完了: 0.24秒\n",
      "  [ステップ3/3] インデックス復元中... (target_original_index: 522,906件, target_df_merged: 522,906件)\n",
      "      target_index_df作成中...\n",
      "      → target_index_df作成完了 (522,906件)\n",
      "      target_index_dfとtarget_df_mergedをmerge実行中...\n",
      "        → merge処理開始...\n",
      "        → merge処理終了 (結果: 522,906件)\n",
      "      merge後のカラム削除中... (現在のカラム数: 388)\n",
      "      → カラム削除完了 (カラム数: 387)\n",
      "      インデックス設定中...\n",
      "      → インデックス設定完了\n",
      "    [ステップ3/3] インデックス復元完了: 1.29秒 (最終結果: 522,906件, カラム数: 387)\n",
      "調教師の統計量を計算中...\n",
      "  target_dfをソート中... (target_df: 522,906件)\n",
      "  ソート完了: 0.88秒\n",
      "  trainer統計量計算: データソート中... (stats: 54,953件, target: 522,906件)\n",
      "  ソート完了: 0.01秒\n",
      "  累積統計量計算中... (グループ数: 490)\n",
      "  累積統計量計算完了: 0.00秒\n",
      "  過去統計量マージ実行中...\n",
      "  グループ処理中: 227グループ\n",
      "  並列処理実行中: 11コア、227グループ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  trainerグループ処理: 100%|██████████| 227/227 [00:00<00:00, 1.03kgroups/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataFrame結合中... (227個のDataFrame)\n",
      "  結合完了: 0.01秒\n",
      "  マージ完了: 0.25秒\n",
      "  統計量計算中...\n",
      "  統計量計算完了: 0.00秒\n",
      "  インデックス復元中... (target: 522,906件)\n",
      "    merge実行中... (merged: 522,906件)\n",
      "  インデックス復元完了: 0.05秒\n",
      "  target_dfにtrainer統計量を結合中... (target_df: 522,906件, trainer_stats: 522,906件)\n",
      "    キー一致確認中...\n",
      "    trainer_statsを列結合中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    列結合完了: 0.23秒 (結果: 522,906件, カラム数: 392)\n",
      "  結合完了: 0.23秒\n",
      "  インデックス復元中... (target_original_index: 522,906件, target_df_merged: 522,906件)\n",
      "      target_index_df作成中...\n",
      "      → target_index_df作成完了 (522,906件)\n",
      "      target_index_dfとtarget_df_mergedをmerge実行中...\n",
      "        → merge処理開始...\n",
      "        → merge処理終了 (結果: 522,906件)\n",
      "      merge後のカラム削除中... (現在のカラム数: 392)\n",
      "      → カラム削除完了 (カラム数: 391)\n",
      "      インデックス設定中...\n",
      "      → インデックス設定完了\n",
      "    インデックス復元完了: 1.29秒 (最終結果: 522,906件, カラム数: 391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "学習用スキーマに定義されているが、データに存在しないカラム: ['course_length', 'course_type', 'frame', 'ground_condition', 'horse_number', 'idm', 'num_horses']\n",
      "学習用スキーマに定義されているが、データに存在しないカラム: ['course_length', 'course_type', 'frame', 'ground_condition', 'horse_number', 'idm', 'num_horses']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "キャッシュに保存しました: training-data_BAC_KYI_SED_TYB_UKC_2024_split-2024-06-01 (Parquet形式, 分割あり)\n",
      "\n",
      "前処理完了: 学習=231,472件, テスト=291,434件\n",
      "レース数: 学習=1464, テスト=1990\n",
      "\n",
      "データ形状: 学習=(231472, 115), テスト=(291434, 115)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込みと前処理を一括実行（CacheManagerを使用）\n",
    "# apps/prediction/を指すように設定（notebooks/から1つ親に上がる）\n",
    "base_project_path = Path().resolve().parent  # notebooks/ -> apps/prediction/\n",
    "cache_manager = CacheManager(base_path=base_project_path)\n",
    "\n",
    "print(\"データ読み込みと前処理を開始します...\")\n",
    "split_date = \"2024-06-01\"  # 分割日時\n",
    "\n",
    "try:\n",
    "    train_df, test_df, original_df = cache_manager.get_or_create(\n",
    "        data_name=\"training-data\",\n",
    "        base_path=BASE_PATH,\n",
    "        data_types=DATA_TYPES,\n",
    "        years=YEARS,\n",
    "        split_date=split_date,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n前処理完了: 学習={len(train_df):,}件, テスト={len(test_df):,}件\")\n",
    "    print(f\"レース数: 学習={train_df.index.nunique() if train_df.index.name == 'race_key' else len(train_df)}, テスト={test_df.index.nunique() if test_df.index.name == 'race_key' else len(test_df)}\")\n",
    "    print(f\"\\nデータ形状: 学習={train_df.shape}, テスト={test_df.shape}\")\n",
    "    \n",
    "    # 学習データとテストデータをdfとval_dfに設定（後続のセルで使用）\n",
    "    df = train_df  # 学習データ\n",
    "    val_df = test_df  # テストデータ（検証データ）\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"エラーが発生しました: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基本統計:\n",
      "       prev_5_time  prev_1_frame        prize_2    weight_type  \\\n",
      "count  3910.000000           0.0  231472.000000  231472.000000   \n",
      "mean   1529.855713           NaN     471.843592       3.240798   \n",
      "std     438.992340           NaN     682.967915       0.784478   \n",
      "min       0.000000           NaN     220.000000       1.000000   \n",
      "25%    1269.000000           NaN     220.000000       3.000000   \n",
      "50%    1486.000000           NaN     320.000000       3.000000   \n",
      "75%    1582.000000           NaN     460.000000       4.000000   \n",
      "max    3192.000000           NaN   12000.000000       4.000000   \n",
      "\n",
      "       prev_1_num_horses  prev_3_distance  jockey_recent_3_time  \\\n",
      "count      156490.000000     40924.000000         229982.000000   \n",
      "mean           14.280491      1674.926758           1524.114258   \n",
      "std             2.578851       380.878815            488.390472   \n",
      "min             6.000000      1000.000000              0.000000   \n",
      "25%            12.000000      1400.000000           1221.000000   \n",
      "50%            15.000000      1700.000000           1466.000000   \n",
      "75%            16.000000      1800.000000           1584.000000   \n",
      "max            18.000000      3390.000000           5066.000000   \n",
      "\n",
      "               round  prev_2_distance   prev_3_time   horse_weight  \\\n",
      "count  231472.000000     89464.000000  40924.000000  229956.000000   \n",
      "mean        1.700931      1672.412109   1525.496948     472.836517   \n",
      "std         0.741625       388.412354    447.496643      31.143864   \n",
      "min         1.000000      1000.000000      0.000000      22.000000   \n",
      "25%         1.000000      1400.000000   1238.000000     452.000000   \n",
      "50%         2.000000      1700.000000   1477.000000     474.000000   \n",
      "75%         2.000000      1800.000000   1582.000000     494.000000   \n",
      "max         3.000000      3400.000000   3526.000000     630.000000   \n",
      "\n",
      "       jockey_recent_2_time  horse_avg_rank  trainer_place_rate  \\\n",
      "count         230860.000000   231472.000000       231472.000000   \n",
      "mean            1492.854370        6.987368            0.213694   \n",
      "std              473.014923        3.551651            0.108699   \n",
      "min                0.000000        0.000000            0.000000   \n",
      "25%             1212.000000        4.000000            0.142857   \n",
      "50%             1439.000000        6.600000            0.214286   \n",
      "75%             1572.000000        9.333333            0.274510   \n",
      "max             5066.000000       18.000000            1.000000   \n",
      "\n",
      "       distance_aptitude  prev_3_num_horses  jockey_recent_3_ground_condition  \\\n",
      "count      231472.000000       40924.000000                     229982.000000   \n",
      "mean            1.949186          14.438666                         14.753007   \n",
      "std             1.820270           2.520386                          7.624291   \n",
      "min             0.000000           6.000000                         10.000000   \n",
      "25%             0.000000          13.000000                         10.000000   \n",
      "50%             2.000000          16.000000                         11.000000   \n",
      "75%             2.000000          16.000000                         20.000000   \n",
      "max             6.000000          18.000000                         41.000000   \n",
      "\n",
      "       prev_4_course_type  paddock_index   prev_3_rank  prev_1_distance  \\\n",
      "count        14242.000000  231472.000000  40924.000000    156490.000000   \n",
      "mean             1.606797       1.025923      6.662887      1673.636963   \n",
      "std              0.516701       1.232401      3.765975       398.972595   \n",
      "min              1.000000       0.000000      0.000000      1000.000000   \n",
      "25%              1.000000       0.000000      4.000000      1400.000000   \n",
      "50%              2.000000       0.000000      6.000000      1700.000000   \n",
      "75%              2.000000       2.200000      9.000000      1800.000000   \n",
      "max              3.000000       3.700000     18.000000      3900.000000   \n",
      "\n",
      "       jockey_recent_1_distance  prev_2_race_num  jockey_recent_2_race_num  \\\n",
      "count             231472.000000              0.0             230860.000000   \n",
      "mean                1661.866211              NaN                  5.204644   \n",
      "std                  407.836395              NaN                  3.694322   \n",
      "min                 1000.000000              NaN                  1.000000   \n",
      "25%                 1400.000000              NaN                  2.000000   \n",
      "50%                 1600.000000              NaN                  4.000000   \n",
      "75%                 1800.000000              NaN                  9.000000   \n",
      "max                 4250.000000              NaN                 12.000000   \n",
      "\n",
      "       prev_5_race_num   prev_4_rank  jockey_race_count  prev_5_course_type  \\\n",
      "count              0.0  14242.000000      231472.000000         3910.000000   \n",
      "mean               NaN      6.928100         108.076018            1.639898   \n",
      "std                NaN      3.731852          82.472997            0.507043   \n",
      "min                NaN      0.000000           1.000000            1.000000   \n",
      "25%                NaN      4.000000          40.000000            1.000000   \n",
      "50%                NaN      6.000000          90.000000            2.000000   \n",
      "75%                NaN      9.000000         160.000000            2.000000   \n",
      "max                NaN     18.000000         393.000000            3.000000   \n",
      "\n",
      "       weight_aptitude  jockey_win_rate  prev_2_frame  prev_1_race_num  \\\n",
      "count    231472.000000    231472.000000           0.0              0.0   \n",
      "mean          2.074048         0.071400           NaN              NaN   \n",
      "std           0.887595         0.064237           NaN              NaN   \n",
      "min           0.000000         0.000000           NaN              NaN   \n",
      "25%           2.000000         0.029412           NaN              NaN   \n",
      "50%           2.000000         0.057778           NaN              NaN   \n",
      "75%           3.000000         0.100000           NaN              NaN   \n",
      "max           3.000000         1.000000           NaN              NaN   \n",
      "\n",
      "       trainer_avg_rank      jockey_id  jockey_weight  prev_4_num_horses  \\\n",
      "count     231472.000000  231472.000000  231472.000000       14242.000000   \n",
      "mean           7.650157   14680.889412     561.139360          14.597388   \n",
      "std            1.244593   14159.256768      17.065977           2.396739   \n",
      "min            1.000000   10324.000000     490.000000           7.000000   \n",
      "25%            6.881356   10521.000000     550.000000          13.000000   \n",
      "50%            7.500000   10581.000000     560.000000          16.000000   \n",
      "75%            8.395833   10611.000000     570.000000          16.000000   \n",
      "max           17.000000   70364.000000     650.000000          18.000000   \n",
      "\n",
      "        prev_4_time  jockey_recent_2_ground_condition  prev_5_rank  \\\n",
      "count  14242.000000                     230860.000000  3910.000000   \n",
      "mean    1534.937988                         14.799012     7.371867   \n",
      "std      430.018341                          7.635805     3.702734   \n",
      "min        0.000000                         10.000000     0.000000   \n",
      "25%     1258.000000                         10.000000     5.000000   \n",
      "50%     1485.000000                         11.000000     7.000000   \n",
      "75%     1588.000000                         20.000000    10.000000   \n",
      "max     3386.000000                         41.000000    17.000000   \n",
      "\n",
      "                 day    total_index  trainer_win_rate  prev_2_horse_number  \\\n",
      "count  219260.000000  231472.000000     231472.000000                  0.0   \n",
      "mean        4.437225      39.505424          0.070175                  NaN   \n",
      "std         2.297646      14.519378          0.058557                  NaN   \n",
      "min         1.000000      -5.900000          0.000000                  NaN   \n",
      "25%         2.000000      29.799999          0.031250                  NaN   \n",
      "50%         4.000000      40.599998          0.063291                  NaN   \n",
      "75%         6.000000      50.000000          0.098901                  NaN   \n",
      "max         9.000000      83.800003          1.000000                  NaN   \n",
      "\n",
      "                time  jockey_recent_1_race_num  jockey_recent_3_rank  \\\n",
      "count  229956.000000             231472.000000         229982.000000   \n",
      "mean      103.630791                  7.350038              7.447748   \n",
      "std        28.226654                  3.549205              4.361538   \n",
      "min         0.000000                  1.000000              0.000000   \n",
      "25%        82.199997                  5.000000              4.000000   \n",
      "50%       106.000000                  7.000000              7.000000   \n",
      "75%       118.000000                 11.000000             11.000000   \n",
      "max       306.600006                 12.000000             18.000000   \n",
      "\n",
      "       prev_2_course_type     trainer_id  prev_4_distance  \\\n",
      "count        89464.000000  231472.000000     14242.000000   \n",
      "mean             1.586940   10533.043409      1680.370728   \n",
      "std              0.534156    1568.976222       365.236481   \n",
      "min              1.000000   10268.000000      1000.000000   \n",
      "25%              1.000000   10371.000000      1400.000000   \n",
      "50%              2.000000   10415.000000      1700.000000   \n",
      "75%              2.000000   10464.000000      1800.000000   \n",
      "max              3.000000   70210.000000      3200.000000   \n",
      "\n",
      "       prev_1_horse_number  prev_5_num_horses      race_mark  \\\n",
      "count                  0.0        3910.000000  231472.000000   \n",
      "mean                   NaN          14.825576      95.084788   \n",
      "std                    NaN           2.192515     131.819188   \n",
      "min                    NaN           7.000000       0.000000   \n",
      "25%                    NaN          14.000000       2.000000   \n",
      "50%                    NaN          16.000000     102.000000   \n",
      "75%                    NaN          16.000000     102.000000   \n",
      "max                    NaN          18.000000     541.000000   \n",
      "\n",
      "       jockey_recent_1_course_type  jockey_recent_3_num_horses   stable_index  \\\n",
      "count                231472.000000               229982.000000  231472.000000   \n",
      "mean                      1.561519                   14.550008       2.364149   \n",
      "std                       0.546311                    2.438065      12.119748   \n",
      "min                       1.000000                    6.000000     -20.000000   \n",
      "25%                       1.000000                   13.000000     -10.000000   \n",
      "50%                       2.000000                   16.000000       4.200000   \n",
      "75%                       2.000000                   16.000000      11.800000   \n",
      "max                       3.000000                   18.000000      40.000000   \n",
      "\n",
      "       prev_2_ground_condition  jockey_recent_1_num_horses  \\\n",
      "count             89464.000000               231472.000000   \n",
      "mean                 15.677725                   14.454318   \n",
      "std                   8.165191                    2.495260   \n",
      "min                  10.000000                    6.000000   \n",
      "25%                  10.000000                   13.000000   \n",
      "50%                  11.000000                   15.000000   \n",
      "75%                  20.000000                   16.000000   \n",
      "max                  41.000000                   18.000000   \n",
      "\n",
      "       jockey_recent_3_distance  jockey_recent_3_race_num  horse_place_rate  \\\n",
      "count             229982.000000             229982.000000     231472.000000   \n",
      "mean                1672.738037                  5.329469          0.244066   \n",
      "std                  408.775696                  3.051469          0.347372   \n",
      "min                 1000.000000                  1.000000          0.000000   \n",
      "25%                 1400.000000                  3.000000          0.000000   \n",
      "50%                 1700.000000                  5.000000          0.000000   \n",
      "75%                 1800.000000                  8.000000          0.500000   \n",
      "max                 4250.000000                 12.000000          1.000000   \n",
      "\n",
      "       prev_3_ground_condition  horse_win_rate  jockey_recent_2_num_horses  \\\n",
      "count             40924.000000   231472.000000                230860.00000   \n",
      "mean                 15.261021        0.068536                    14.72482   \n",
      "std                   8.138656        0.193403                     2.29226   \n",
      "min                  10.000000        0.000000                     6.00000   \n",
      "25%                  10.000000        0.000000                    14.00000   \n",
      "50%                  11.000000        0.000000                    16.00000   \n",
      "75%                  20.000000        0.000000                    16.00000   \n",
      "max                  41.000000        1.000000                    18.00000   \n",
      "\n",
      "               place  prev_5_ground_condition  prev_1_course_type  \\\n",
      "count  231472.000000              3910.000000       156490.000000   \n",
      "mean        6.956306                14.680819            1.582925   \n",
      "std         2.044956                 8.254299            0.540084   \n",
      "min         3.000000                10.000000            1.000000   \n",
      "25%         5.000000                10.000000            1.000000   \n",
      "50%         7.000000                11.000000            2.000000   \n",
      "75%         9.000000                11.000000            2.000000   \n",
      "max        10.000000                41.000000            3.000000   \n",
      "\n",
      "       training_index  course_setting    prev_1_rank  \\\n",
      "count   231472.000000   231472.000000  156490.000000   \n",
      "mean         1.505522        1.371527       6.639734   \n",
      "std         10.618099        1.364482       4.032385   \n",
      "min        -20.000000        1.000000       0.000000   \n",
      "25%         -8.800000        1.000000       3.000000   \n",
      "50%          0.700000        1.000000       6.000000   \n",
      "75%         10.700000        1.000000       9.000000   \n",
      "max         26.000000        9.000000      18.000000   \n",
      "\n",
      "       jockey_recent_3_course_type     race_class  prev_4_horse_number  \\\n",
      "count                229982.000000  231472.000000                  0.0   \n",
      "mean                      1.609404      13.149806                  NaN   \n",
      "std                       0.539437       1.505651                  NaN   \n",
      "min                       1.000000      12.000000                  NaN   \n",
      "25%                       1.000000      12.000000                  NaN   \n",
      "50%                       2.000000      12.000000                  NaN   \n",
      "75%                       2.000000      14.000000                  NaN   \n",
      "max                       3.000000      20.000000                  NaN   \n",
      "\n",
      "       prev_4_frame   prev_2_rank            age  jockey_recent_2_distance  \\\n",
      "count           0.0  89464.000000  231472.000000             230860.000000   \n",
      "mean            NaN      6.575382       3.922643               1652.483887   \n",
      "std             NaN      3.888446       1.180045                404.058594   \n",
      "min             NaN      0.000000       2.000000               1000.000000   \n",
      "25%             NaN      3.000000       3.000000               1400.000000   \n",
      "50%             NaN      6.000000       3.000000               1700.000000   \n",
      "75%             NaN      9.000000       5.000000               1800.000000   \n",
      "max             NaN     18.000000      12.000000               4250.000000   \n",
      "\n",
      "       jockey_recent_1_ground_condition  jockey_recent_1_time  \\\n",
      "count                     231472.000000         231472.000000   \n",
      "mean                          14.595096           1496.591919   \n",
      "std                            7.469311            484.728302   \n",
      "min                           10.000000              0.000000   \n",
      "25%                           10.000000           1202.000000   \n",
      "50%                           11.000000           1390.000000   \n",
      "75%                           20.000000           1572.000000   \n",
      "max                           41.000000           5066.000000   \n",
      "\n",
      "       prev_2_num_horses    race_number  prev_3_course_type      horse_id  \\\n",
      "count       89464.000000  231472.000000        40924.000000  2.314720e+05   \n",
      "mean           14.329518       6.552404            1.601163  2.018050e+07   \n",
      "std             2.559269       3.498403            0.527155  1.180043e+06   \n",
      "min             6.000000       1.000000            1.000000  1.210068e+07   \n",
      "25%            12.000000       3.000000            1.000000  1.910640e+07   \n",
      "50%            15.000000       7.000000            2.000000  2.110011e+07   \n",
      "75%            16.000000      10.000000            2.000000  2.110412e+07   \n",
      "max            18.000000      12.000000            3.000000  2.111017e+07   \n",
      "\n",
      "             prize_3    prev_1_time  prev_3_race_num  trainer_race_count  \\\n",
      "count  231472.000000  156490.000000              0.0       231472.000000   \n",
      "mean      297.155077    1521.103760              NaN           58.713132   \n",
      "std       428.426480     463.656433              NaN           36.121683   \n",
      "min       140.000000       0.000000              NaN            1.000000   \n",
      "25%       140.000000    1220.000000              NaN           29.000000   \n",
      "50%       200.000000    1466.000000              NaN           57.000000   \n",
      "75%       290.000000    1579.000000              NaN           85.000000   \n",
      "max      7500.000000    4269.000000              NaN          206.000000   \n",
      "\n",
      "       prev_1_ground_condition  jockey_recent_2_rank  prev_3_horse_number  \\\n",
      "count            156490.000000         230860.000000                  0.0   \n",
      "mean                 15.459544              7.378983                  NaN   \n",
      "std                   7.959581              4.420286                  NaN   \n",
      "min                  10.000000              0.000000                  NaN   \n",
      "25%                  10.000000              4.000000                  NaN   \n",
      "50%                  11.000000              7.000000                  NaN   \n",
      "75%                  20.000000             11.000000                  NaN   \n",
      "max                  41.000000             18.000000                  NaN   \n",
      "\n",
      "             prize_1  prev_5_distance  jockey_avg_rank  jockey_recent_1_rank  \\\n",
      "count  231472.000000      3910.000000    231472.000000         231472.000000   \n",
      "mean     1178.732374      1679.007690         7.649719              7.462051   \n",
      "std      1707.347998       357.060913         1.526067              4.443702   \n",
      "min       550.000000      1000.000000         1.000000              0.000000   \n",
      "25%       550.000000      1400.000000         6.631579              4.000000   \n",
      "50%       800.000000      1700.000000         7.719626              7.000000   \n",
      "75%      1140.000000      1800.000000         8.666667             11.000000   \n",
      "max     30000.000000      2860.000000        16.000000             18.000000   \n",
      "\n",
      "       prev_4_race_num  prev_5_frame        weather  horse_weight_diff  \\\n",
      "count              0.0           0.0  229956.000000       65740.000000   \n",
      "mean               NaN           NaN       1.499809           0.800578   \n",
      "std                NaN           NaN       0.755901          12.881325   \n",
      "min                NaN           NaN       0.000000         -36.000000   \n",
      "25%                NaN           NaN       1.000000           0.000000   \n",
      "50%                NaN           NaN       1.000000           0.000000   \n",
      "75%                NaN           NaN       2.000000           0.000000   \n",
      "max                NaN           NaN       4.000000         222.000000   \n",
      "\n",
      "                rank   prev_2_time     info_index  horse_race_count  \\\n",
      "count  229956.000000  89464.000000  231472.000000     231472.000000   \n",
      "mean        7.018116   1521.095093       0.924074          2.321473   \n",
      "std         4.159255    453.956512       1.503223          1.264086   \n",
      "min         1.000000      0.000000      -2.000000          1.000000   \n",
      "25%         4.000000   1226.000000       0.000000          1.000000   \n",
      "50%         7.000000   1471.000000       0.300000          2.000000   \n",
      "75%        10.000000   1580.000000       2.100000          3.000000   \n",
      "max        18.000000   3561.000000       6.400000          9.000000   \n",
      "\n",
      "       prev_4_ground_condition  prev_5_horse_number  start_datetime  \\\n",
      "count             14242.000000                  0.0    2.314720e+05   \n",
      "mean                 14.853953                  NaN    2.024032e+11   \n",
      "std                   8.041569                  NaN    1.385615e+06   \n",
      "min                  10.000000                  NaN    2.024011e+11   \n",
      "25%                  10.000000                  NaN    2.024021e+11   \n",
      "50%                  11.000000                  NaN    2.024032e+11   \n",
      "75%                  20.000000                  NaN    2.024042e+11   \n",
      "max                  41.000000                  NaN    2.024053e+11   \n",
      "\n",
      "                 sex  prev_3_frame  jockey_recent_2_course_type  \\\n",
      "count  231472.000000           0.0                230860.000000   \n",
      "mean        1.479807           NaN                     1.657429   \n",
      "std         0.582849           NaN                     0.526462   \n",
      "min         1.000000           NaN                     1.000000   \n",
      "25%         1.000000           NaN                     1.000000   \n",
      "50%         1.000000           NaN                     2.000000   \n",
      "75%         2.000000           NaN                     2.000000   \n",
      "max         3.000000           NaN                     3.000000   \n",
      "\n",
      "        jockey_index  jockey_place_rate  running_style  \n",
      "count  231472.000000      231472.000000  231472.000000  \n",
      "mean        0.927978           0.215228       2.619012  \n",
      "std         0.830659           0.123054       1.119591  \n",
      "min         0.000000           0.000000       0.000000  \n",
      "25%         0.300000           0.132812       2.000000  \n",
      "50%         0.600000           0.189655       3.000000  \n",
      "75%         1.400000           0.285714       3.000000  \n",
      "max         3.900000           1.000000       4.000000  \n",
      "\n",
      "欠損値:\n",
      "prev_2_horse_number        231472\n",
      "prev_3_race_num            231472\n",
      "prev_5_race_num            231472\n",
      "prev_1_horse_number        231472\n",
      "prev_3_horse_number        231472\n",
      "prev_3_frame               231472\n",
      "prev_2_race_num            231472\n",
      "prev_4_race_num            231472\n",
      "prev_5_horse_number        231472\n",
      "prev_4_horse_number        231472\n",
      "prev_5_frame               231472\n",
      "prev_4_frame               231472\n",
      "prev_2_frame               231472\n",
      "prev_1_race_num            231472\n",
      "prev_1_frame               231472\n",
      "prev_5_ground_condition    227562\n",
      "prev_5_time                227562\n",
      "prev_5_distance            227562\n",
      "prev_5_course_type         227562\n",
      "prev_5_num_horses          227562\n",
      "dtype: int64\n",
      "\n",
      "着順の分布（original_dfから）:\n",
      "rank\n",
      "1.0     39202\n",
      "2.0     43572\n",
      "3.0     43252\n",
      "4.0     43368\n",
      "5.0     42708\n",
      "6.0     40710\n",
      "7.0     39436\n",
      "8.0     37734\n",
      "9.0     35304\n",
      "10.0    32178\n",
      "11.0    28614\n",
      "12.0    25342\n",
      "13.0    21544\n",
      "14.0    18148\n",
      "15.0    14180\n",
      "16.0     9532\n",
      "17.0     2464\n",
      "18.0     1656\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "データの上位50件:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stable</th>\n",
       "      <th>prev_5_time</th>\n",
       "      <th>prev_1_frame</th>\n",
       "      <th>prize_2</th>\n",
       "      <th>weight_type</th>\n",
       "      <th>prev_1_num_horses</th>\n",
       "      <th>prev_3_distance</th>\n",
       "      <th>jockey_recent_3_time</th>\n",
       "      <th>round</th>\n",
       "      <th>prev_2_distance</th>\n",
       "      <th>prev_3_time</th>\n",
       "      <th>horse_weight</th>\n",
       "      <th>jockey_recent_2_time</th>\n",
       "      <th>horse_avg_rank</th>\n",
       "      <th>trainer_place_rate</th>\n",
       "      <th>distance_aptitude</th>\n",
       "      <th>prev_3_num_horses</th>\n",
       "      <th>jockey_recent_3_ground_condition</th>\n",
       "      <th>prev_4_course_type</th>\n",
       "      <th>paddock_index</th>\n",
       "      <th>prev_3_rank</th>\n",
       "      <th>prev_1_distance</th>\n",
       "      <th>jockey_recent_1_distance</th>\n",
       "      <th>prev_2_race_num</th>\n",
       "      <th>jockey_recent_2_race_num</th>\n",
       "      <th>prev_5_race_num</th>\n",
       "      <th>prev_4_rank</th>\n",
       "      <th>jockey_race_count</th>\n",
       "      <th>prev_5_course_type</th>\n",
       "      <th>race_grade</th>\n",
       "      <th>weight_aptitude</th>\n",
       "      <th>jockey_win_rate</th>\n",
       "      <th>prev_2_frame</th>\n",
       "      <th>prev_1_race_num</th>\n",
       "      <th>trainer_avg_rank</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>jockey_weight</th>\n",
       "      <th>prev_4_num_horses</th>\n",
       "      <th>prev_4_time</th>\n",
       "      <th>jockey_recent_2_ground_condition</th>\n",
       "      <th>prev_5_rank</th>\n",
       "      <th>day</th>\n",
       "      <th>total_index</th>\n",
       "      <th>trainer_win_rate</th>\n",
       "      <th>prev_2_horse_number</th>\n",
       "      <th>time</th>\n",
       "      <th>jockey_recent_1_race_num</th>\n",
       "      <th>jockey_recent_3_rank</th>\n",
       "      <th>prev_2_course_type</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>prev_4_distance</th>\n",
       "      <th>prev_1_horse_number</th>\n",
       "      <th>prev_5_num_horses</th>\n",
       "      <th>race_mark</th>\n",
       "      <th>jockey_recent_1_course_type</th>\n",
       "      <th>jockey_recent_3_num_horses</th>\n",
       "      <th>stable_index</th>\n",
       "      <th>prev_2_ground_condition</th>\n",
       "      <th>jockey_recent_1_num_horses</th>\n",
       "      <th>jockey_recent_3_distance</th>\n",
       "      <th>dirt_aptitude</th>\n",
       "      <th>jockey_recent_3_race_num</th>\n",
       "      <th>horse_place_rate</th>\n",
       "      <th>prev_3_ground_condition</th>\n",
       "      <th>horse_win_rate</th>\n",
       "      <th>jockey_recent_2_num_horses</th>\n",
       "      <th>place</th>\n",
       "      <th>prev_5_ground_condition</th>\n",
       "      <th>prev_1_course_type</th>\n",
       "      <th>training_index</th>\n",
       "      <th>course_setting</th>\n",
       "      <th>prev_1_rank</th>\n",
       "      <th>jockey_recent_3_course_type</th>\n",
       "      <th>race_class</th>\n",
       "      <th>prev_4_horse_number</th>\n",
       "      <th>prev_4_frame</th>\n",
       "      <th>prev_2_rank</th>\n",
       "      <th>age</th>\n",
       "      <th>jockey_recent_2_distance</th>\n",
       "      <th>jockey_recent_1_ground_condition</th>\n",
       "      <th>jockey_recent_1_time</th>\n",
       "      <th>prev_2_num_horses</th>\n",
       "      <th>race_number</th>\n",
       "      <th>prev_3_course_type</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>prize_3</th>\n",
       "      <th>turf_aptitude</th>\n",
       "      <th>prev_1_time</th>\n",
       "      <th>prev_3_race_num</th>\n",
       "      <th>trainer_race_count</th>\n",
       "      <th>prev_1_ground_condition</th>\n",
       "      <th>jockey_recent_2_rank</th>\n",
       "      <th>prev_3_horse_number</th>\n",
       "      <th>prize_1</th>\n",
       "      <th>prev_5_distance</th>\n",
       "      <th>jockey_avg_rank</th>\n",
       "      <th>jockey_recent_1_rank</th>\n",
       "      <th>prev_4_race_num</th>\n",
       "      <th>prev_5_frame</th>\n",
       "      <th>weather</th>\n",
       "      <th>horse_weight_diff</th>\n",
       "      <th>rank</th>\n",
       "      <th>prev_2_time</th>\n",
       "      <th>info_index</th>\n",
       "      <th>horse_race_count</th>\n",
       "      <th>prev_4_ground_condition</th>\n",
       "      <th>prev_5_horse_number</th>\n",
       "      <th>start_datetime</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_condition</th>\n",
       "      <th>prev_3_frame</th>\n",
       "      <th>jockey_recent_2_course_type</th>\n",
       "      <th>jockey_index</th>\n",
       "      <th>jockey_place_rate</th>\n",
       "      <th>running_style</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>10578</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.599998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.900002</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21105640</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>2</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10522</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.300003</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21102836</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10522</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.300003</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21102836</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10522</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.300003</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21102836</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10522</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.300003</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21102836</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>10598</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21106754</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>10598</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21106754</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>10598</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21106754</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>10598</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21106754</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240106_08_01_1_01</th>\n",
       "      <td>栗東</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>10598</td>\n",
       "      <td>570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21106754</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202401060950</td>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    stable  prev_5_time  prev_1_frame  prize_2  weight_type  \\\n",
       "race_key                                                                      \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "20240106_08_01_1_01     栗東          NaN           NaN      220            3   \n",
       "\n",
       "                     prev_1_num_horses  prev_3_distance  jockey_recent_3_time  \\\n",
       "race_key                                                                        \n",
       "20240106_08_01_1_01                NaN              NaN                1242.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1563.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1563.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1563.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1563.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1568.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1568.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1568.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1568.0   \n",
       "20240106_08_01_1_01                NaN              NaN                1568.0   \n",
       "\n",
       "                     round  prev_2_distance  prev_3_time  horse_weight  \\\n",
       "race_key                                                                 \n",
       "20240106_08_01_1_01      1              NaN          NaN         442.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         530.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         530.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         530.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         530.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         496.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         496.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         496.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         496.0   \n",
       "20240106_08_01_1_01      1              NaN          NaN         496.0   \n",
       "\n",
       "                     jockey_recent_2_time  horse_avg_rank  trainer_place_rate  \\\n",
       "race_key                                                                        \n",
       "20240106_08_01_1_01                1348.0             3.0            0.500000   \n",
       "20240106_08_01_1_01                1100.0             6.0            0.000000   \n",
       "20240106_08_01_1_01                1100.0             6.0            0.000000   \n",
       "20240106_08_01_1_01                1100.0             6.0            0.000000   \n",
       "20240106_08_01_1_01                1100.0             6.0            0.000000   \n",
       "20240106_08_01_1_01                2031.0            13.0            0.666667   \n",
       "20240106_08_01_1_01                2031.0            13.0            0.666667   \n",
       "20240106_08_01_1_01                2031.0            13.0            0.666667   \n",
       "20240106_08_01_1_01                2031.0            13.0            0.666667   \n",
       "20240106_08_01_1_01                2031.0            13.0            0.666667   \n",
       "\n",
       "                     distance_aptitude  prev_3_num_horses  \\\n",
       "race_key                                                    \n",
       "20240106_08_01_1_01                  2                NaN   \n",
       "20240106_08_01_1_01                  2                NaN   \n",
       "20240106_08_01_1_01                  2                NaN   \n",
       "20240106_08_01_1_01                  2                NaN   \n",
       "20240106_08_01_1_01                  2                NaN   \n",
       "20240106_08_01_1_01                  5                NaN   \n",
       "20240106_08_01_1_01                  5                NaN   \n",
       "20240106_08_01_1_01                  5                NaN   \n",
       "20240106_08_01_1_01                  5                NaN   \n",
       "20240106_08_01_1_01                  5                NaN   \n",
       "\n",
       "                     jockey_recent_3_ground_condition  prev_4_course_type  \\\n",
       "race_key                                                                    \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "20240106_08_01_1_01                              10.0                 NaN   \n",
       "\n",
       "                     paddock_index  prev_3_rank  prev_1_distance  \\\n",
       "race_key                                                           \n",
       "20240106_08_01_1_01            1.8          NaN              NaN   \n",
       "20240106_08_01_1_01            2.0          NaN              NaN   \n",
       "20240106_08_01_1_01            2.0          NaN              NaN   \n",
       "20240106_08_01_1_01            2.0          NaN              NaN   \n",
       "20240106_08_01_1_01            2.0          NaN              NaN   \n",
       "20240106_08_01_1_01            0.0          NaN              NaN   \n",
       "20240106_08_01_1_01            0.0          NaN              NaN   \n",
       "20240106_08_01_1_01            0.0          NaN              NaN   \n",
       "20240106_08_01_1_01            0.0          NaN              NaN   \n",
       "20240106_08_01_1_01            0.0          NaN              NaN   \n",
       "\n",
       "                     jockey_recent_1_distance  prev_2_race_num  \\\n",
       "race_key                                                         \n",
       "20240106_08_01_1_01                    1800.0              NaN   \n",
       "20240106_08_01_1_01                    1600.0              NaN   \n",
       "20240106_08_01_1_01                    1600.0              NaN   \n",
       "20240106_08_01_1_01                    1600.0              NaN   \n",
       "20240106_08_01_1_01                    1600.0              NaN   \n",
       "20240106_08_01_1_01                    1400.0              NaN   \n",
       "20240106_08_01_1_01                    1400.0              NaN   \n",
       "20240106_08_01_1_01                    1400.0              NaN   \n",
       "20240106_08_01_1_01                    1400.0              NaN   \n",
       "20240106_08_01_1_01                    1400.0              NaN   \n",
       "\n",
       "                     jockey_recent_2_race_num  prev_5_race_num  prev_4_rank  \\\n",
       "race_key                                                                      \n",
       "20240106_08_01_1_01                      11.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       6.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       6.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       6.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       6.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       2.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       2.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       2.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       2.0              NaN          NaN   \n",
       "20240106_08_01_1_01                       2.0              NaN          NaN   \n",
       "\n",
       "                     jockey_race_count  prev_5_course_type race_grade  \\\n",
       "race_key                                                                \n",
       "20240106_08_01_1_01                  8                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "20240106_08_01_1_01                  3                 NaN              \n",
       "\n",
       "                     weight_aptitude  jockey_win_rate  prev_2_frame  \\\n",
       "race_key                                                              \n",
       "20240106_08_01_1_01              3.0              0.0           NaN   \n",
       "20240106_08_01_1_01              3.0              0.0           NaN   \n",
       "20240106_08_01_1_01              3.0              0.0           NaN   \n",
       "20240106_08_01_1_01              3.0              0.0           NaN   \n",
       "20240106_08_01_1_01              3.0              0.0           NaN   \n",
       "20240106_08_01_1_01              2.0              0.0           NaN   \n",
       "20240106_08_01_1_01              2.0              0.0           NaN   \n",
       "20240106_08_01_1_01              2.0              0.0           NaN   \n",
       "20240106_08_01_1_01              2.0              0.0           NaN   \n",
       "20240106_08_01_1_01              2.0              0.0           NaN   \n",
       "\n",
       "                     prev_1_race_num  trainer_avg_rank  jockey_id  \\\n",
       "race_key                                                            \n",
       "20240106_08_01_1_01              NaN          5.500000      10578   \n",
       "20240106_08_01_1_01              NaN         10.000000      10522   \n",
       "20240106_08_01_1_01              NaN         10.000000      10522   \n",
       "20240106_08_01_1_01              NaN         10.000000      10522   \n",
       "20240106_08_01_1_01              NaN         10.000000      10522   \n",
       "20240106_08_01_1_01              NaN          5.666667      10598   \n",
       "20240106_08_01_1_01              NaN          5.666667      10598   \n",
       "20240106_08_01_1_01              NaN          5.666667      10598   \n",
       "20240106_08_01_1_01              NaN          5.666667      10598   \n",
       "20240106_08_01_1_01              NaN          5.666667      10598   \n",
       "\n",
       "                     jockey_weight  prev_4_num_horses  prev_4_time  \\\n",
       "race_key                                                             \n",
       "20240106_08_01_1_01            550                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "20240106_08_01_1_01            570                NaN          NaN   \n",
       "\n",
       "                     jockey_recent_2_ground_condition  prev_5_rank  day  \\\n",
       "race_key                                                                  \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              11.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              11.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              11.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              11.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "20240106_08_01_1_01                              10.0          NaN  1.0   \n",
       "\n",
       "                     total_index  trainer_win_rate  prev_2_horse_number  \\\n",
       "race_key                                                                  \n",
       "20240106_08_01_1_01    32.599998          0.000000                  NaN   \n",
       "20240106_08_01_1_01    27.600000          0.000000                  NaN   \n",
       "20240106_08_01_1_01    27.600000          0.000000                  NaN   \n",
       "20240106_08_01_1_01    27.600000          0.000000                  NaN   \n",
       "20240106_08_01_1_01    27.600000          0.000000                  NaN   \n",
       "20240106_08_01_1_01    19.299999          0.333333                  NaN   \n",
       "20240106_08_01_1_01    19.299999          0.333333                  NaN   \n",
       "20240106_08_01_1_01    19.299999          0.333333                  NaN   \n",
       "20240106_08_01_1_01    19.299999          0.333333                  NaN   \n",
       "20240106_08_01_1_01    19.299999          0.333333                  NaN   \n",
       "\n",
       "                           time  jockey_recent_1_race_num  \\\n",
       "race_key                                                    \n",
       "20240106_08_01_1_01  115.900002                      12.0   \n",
       "20240106_08_01_1_01  116.300003                      11.0   \n",
       "20240106_08_01_1_01  116.300003                      11.0   \n",
       "20240106_08_01_1_01  116.300003                      11.0   \n",
       "20240106_08_01_1_01  116.300003                      11.0   \n",
       "20240106_08_01_1_01  116.800003                       9.0   \n",
       "20240106_08_01_1_01  116.800003                       9.0   \n",
       "20240106_08_01_1_01  116.800003                       9.0   \n",
       "20240106_08_01_1_01  116.800003                       9.0   \n",
       "20240106_08_01_1_01  116.800003                       9.0   \n",
       "\n",
       "                     jockey_recent_3_rank  prev_2_course_type  trainer_id  \\\n",
       "race_key                                                                    \n",
       "20240106_08_01_1_01                   3.0                 NaN       10385   \n",
       "20240106_08_01_1_01                   6.0                 NaN       10448   \n",
       "20240106_08_01_1_01                   6.0                 NaN       10448   \n",
       "20240106_08_01_1_01                   6.0                 NaN       10448   \n",
       "20240106_08_01_1_01                   6.0                 NaN       10448   \n",
       "20240106_08_01_1_01                  13.0                 NaN       10447   \n",
       "20240106_08_01_1_01                  13.0                 NaN       10447   \n",
       "20240106_08_01_1_01                  13.0                 NaN       10447   \n",
       "20240106_08_01_1_01                  13.0                 NaN       10447   \n",
       "20240106_08_01_1_01                  13.0                 NaN       10447   \n",
       "\n",
       "                     prev_4_distance  prev_1_horse_number  prev_5_num_horses  \\\n",
       "race_key                                                                       \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "20240106_08_01_1_01              NaN                  NaN                NaN   \n",
       "\n",
       "                     race_mark  jockey_recent_1_course_type  \\\n",
       "race_key                                                      \n",
       "20240106_08_01_1_01        102                          1.0   \n",
       "20240106_08_01_1_01        102                          1.0   \n",
       "20240106_08_01_1_01        102                          1.0   \n",
       "20240106_08_01_1_01        102                          1.0   \n",
       "20240106_08_01_1_01        102                          1.0   \n",
       "20240106_08_01_1_01        102                          2.0   \n",
       "20240106_08_01_1_01        102                          2.0   \n",
       "20240106_08_01_1_01        102                          2.0   \n",
       "20240106_08_01_1_01        102                          2.0   \n",
       "20240106_08_01_1_01        102                          2.0   \n",
       "\n",
       "                     jockey_recent_3_num_horses  stable_index  \\\n",
       "race_key                                                        \n",
       "20240106_08_01_1_01                        12.0           1.5   \n",
       "20240106_08_01_1_01                        16.0          -1.2   \n",
       "20240106_08_01_1_01                        16.0          -1.2   \n",
       "20240106_08_01_1_01                        16.0          -1.2   \n",
       "20240106_08_01_1_01                        16.0          -1.2   \n",
       "20240106_08_01_1_01                        16.0           8.7   \n",
       "20240106_08_01_1_01                        16.0           8.7   \n",
       "20240106_08_01_1_01                        16.0           8.7   \n",
       "20240106_08_01_1_01                        16.0           8.7   \n",
       "20240106_08_01_1_01                        16.0           8.7   \n",
       "\n",
       "                     prev_2_ground_condition  jockey_recent_1_num_horses  \\\n",
       "race_key                                                                   \n",
       "20240106_08_01_1_01                      NaN                        17.0   \n",
       "20240106_08_01_1_01                      NaN                        18.0   \n",
       "20240106_08_01_1_01                      NaN                        18.0   \n",
       "20240106_08_01_1_01                      NaN                        18.0   \n",
       "20240106_08_01_1_01                      NaN                        18.0   \n",
       "20240106_08_01_1_01                      NaN                        12.0   \n",
       "20240106_08_01_1_01                      NaN                        12.0   \n",
       "20240106_08_01_1_01                      NaN                        12.0   \n",
       "20240106_08_01_1_01                      NaN                        12.0   \n",
       "20240106_08_01_1_01                      NaN                        12.0   \n",
       "\n",
       "                     jockey_recent_3_distance dirt_aptitude  \\\n",
       "race_key                                                      \n",
       "20240106_08_01_1_01                    1400.0             2   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "20240106_08_01_1_01                    1800.0             3   \n",
       "\n",
       "                     jockey_recent_3_race_num  horse_place_rate  \\\n",
       "race_key                                                          \n",
       "20240106_08_01_1_01                       9.0               1.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "20240106_08_01_1_01                       1.0               0.0   \n",
       "\n",
       "                     prev_3_ground_condition  horse_win_rate  \\\n",
       "race_key                                                       \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "20240106_08_01_1_01                      NaN             0.0   \n",
       "\n",
       "                     jockey_recent_2_num_horses  place  \\\n",
       "race_key                                                 \n",
       "20240106_08_01_1_01                        18.0      8   \n",
       "20240106_08_01_1_01                        10.0      8   \n",
       "20240106_08_01_1_01                        10.0      8   \n",
       "20240106_08_01_1_01                        10.0      8   \n",
       "20240106_08_01_1_01                        10.0      8   \n",
       "20240106_08_01_1_01                        16.0      8   \n",
       "20240106_08_01_1_01                        16.0      8   \n",
       "20240106_08_01_1_01                        16.0      8   \n",
       "20240106_08_01_1_01                        16.0      8   \n",
       "20240106_08_01_1_01                        16.0      8   \n",
       "\n",
       "                     prev_5_ground_condition  prev_1_course_type  \\\n",
       "race_key                                                           \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "20240106_08_01_1_01                      NaN                 NaN   \n",
       "\n",
       "                     training_index  course_setting  prev_1_rank  \\\n",
       "race_key                                                           \n",
       "20240106_08_01_1_01            -4.1               1          NaN   \n",
       "20240106_08_01_1_01             1.2               1          NaN   \n",
       "20240106_08_01_1_01             1.2               1          NaN   \n",
       "20240106_08_01_1_01             1.2               1          NaN   \n",
       "20240106_08_01_1_01             1.2               1          NaN   \n",
       "20240106_08_01_1_01            -5.9               1          NaN   \n",
       "20240106_08_01_1_01            -5.9               1          NaN   \n",
       "20240106_08_01_1_01            -5.9               1          NaN   \n",
       "20240106_08_01_1_01            -5.9               1          NaN   \n",
       "20240106_08_01_1_01            -5.9               1          NaN   \n",
       "\n",
       "                     jockey_recent_3_course_type  race_class  \\\n",
       "race_key                                                       \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "20240106_08_01_1_01                          2.0          12   \n",
       "\n",
       "                     prev_4_horse_number  prev_4_frame  prev_2_rank  age  \\\n",
       "race_key                                                                   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "20240106_08_01_1_01                  NaN           NaN          NaN    3   \n",
       "\n",
       "                     jockey_recent_2_distance  \\\n",
       "race_key                                        \n",
       "20240106_08_01_1_01                    1600.0   \n",
       "20240106_08_01_1_01                    1200.0   \n",
       "20240106_08_01_1_01                    1200.0   \n",
       "20240106_08_01_1_01                    1200.0   \n",
       "20240106_08_01_1_01                    1200.0   \n",
       "20240106_08_01_1_01                    1900.0   \n",
       "20240106_08_01_1_01                    1900.0   \n",
       "20240106_08_01_1_01                    1900.0   \n",
       "20240106_08_01_1_01                    1900.0   \n",
       "20240106_08_01_1_01                    1900.0   \n",
       "\n",
       "                     jockey_recent_1_ground_condition  jockey_recent_1_time  \\\n",
       "race_key                                                                      \n",
       "20240106_08_01_1_01                              10.0                1475.0   \n",
       "20240106_08_01_1_01                              10.0                1346.0   \n",
       "20240106_08_01_1_01                              10.0                1346.0   \n",
       "20240106_08_01_1_01                              10.0                1346.0   \n",
       "20240106_08_01_1_01                              10.0                1346.0   \n",
       "20240106_08_01_1_01                              10.0                1236.0   \n",
       "20240106_08_01_1_01                              10.0                1236.0   \n",
       "20240106_08_01_1_01                              10.0                1236.0   \n",
       "20240106_08_01_1_01                              10.0                1236.0   \n",
       "20240106_08_01_1_01                              10.0                1236.0   \n",
       "\n",
       "                     prev_2_num_horses  race_number  prev_3_course_type  \\\n",
       "race_key                                                                  \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "20240106_08_01_1_01                NaN            1                 NaN   \n",
       "\n",
       "                     horse_id  prize_3 turf_aptitude  prev_1_time  \\\n",
       "race_key                                                            \n",
       "20240106_08_01_1_01  21105640      140                        NaN   \n",
       "20240106_08_01_1_01  21102836      140                        NaN   \n",
       "20240106_08_01_1_01  21102836      140                        NaN   \n",
       "20240106_08_01_1_01  21102836      140                        NaN   \n",
       "20240106_08_01_1_01  21102836      140                        NaN   \n",
       "20240106_08_01_1_01  21106754      140                        NaN   \n",
       "20240106_08_01_1_01  21106754      140                        NaN   \n",
       "20240106_08_01_1_01  21106754      140                        NaN   \n",
       "20240106_08_01_1_01  21106754      140                        NaN   \n",
       "20240106_08_01_1_01  21106754      140                        NaN   \n",
       "\n",
       "                     prev_3_race_num  trainer_race_count  \\\n",
       "race_key                                                   \n",
       "20240106_08_01_1_01              NaN                   4   \n",
       "20240106_08_01_1_01              NaN                   2   \n",
       "20240106_08_01_1_01              NaN                   2   \n",
       "20240106_08_01_1_01              NaN                   2   \n",
       "20240106_08_01_1_01              NaN                   2   \n",
       "20240106_08_01_1_01              NaN                   3   \n",
       "20240106_08_01_1_01              NaN                   3   \n",
       "20240106_08_01_1_01              NaN                   3   \n",
       "20240106_08_01_1_01              NaN                   3   \n",
       "20240106_08_01_1_01              NaN                   3   \n",
       "\n",
       "                     prev_1_ground_condition  jockey_recent_2_rank  \\\n",
       "race_key                                                             \n",
       "20240106_08_01_1_01                      NaN                  11.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "20240106_08_01_1_01                      NaN                   4.0   \n",
       "\n",
       "                     prev_3_horse_number  prize_1  prev_5_distance  \\\n",
       "race_key                                                             \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "20240106_08_01_1_01                  NaN      550              NaN   \n",
       "\n",
       "                     jockey_avg_rank  jockey_recent_1_rank  prev_4_race_num  \\\n",
       "race_key                                                                      \n",
       "20240106_08_01_1_01         7.250000                   3.0              NaN   \n",
       "20240106_08_01_1_01         6.000000                   8.0              NaN   \n",
       "20240106_08_01_1_01         6.000000                   8.0              NaN   \n",
       "20240106_08_01_1_01         6.000000                   8.0              NaN   \n",
       "20240106_08_01_1_01         6.000000                   8.0              NaN   \n",
       "20240106_08_01_1_01         6.333333                   2.0              NaN   \n",
       "20240106_08_01_1_01         6.333333                   2.0              NaN   \n",
       "20240106_08_01_1_01         6.333333                   2.0              NaN   \n",
       "20240106_08_01_1_01         6.333333                   2.0              NaN   \n",
       "20240106_08_01_1_01         6.333333                   2.0              NaN   \n",
       "\n",
       "                     prev_5_frame  weather  horse_weight_diff  rank  \\\n",
       "race_key                                                              \n",
       "20240106_08_01_1_01           NaN      1.0                NaN   3.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN   6.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN   6.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN   6.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN   6.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN  13.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN  13.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN  13.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN  13.0   \n",
       "20240106_08_01_1_01           NaN      1.0                NaN  13.0   \n",
       "\n",
       "                     prev_2_time  info_index  horse_race_count  \\\n",
       "race_key                                                         \n",
       "20240106_08_01_1_01          NaN         0.0                 1   \n",
       "20240106_08_01_1_01          NaN         0.0                 1   \n",
       "20240106_08_01_1_01          NaN         0.0                 1   \n",
       "20240106_08_01_1_01          NaN         0.0                 1   \n",
       "20240106_08_01_1_01          NaN         0.0                 1   \n",
       "20240106_08_01_1_01          NaN         0.1                 1   \n",
       "20240106_08_01_1_01          NaN         0.1                 1   \n",
       "20240106_08_01_1_01          NaN         0.1                 1   \n",
       "20240106_08_01_1_01          NaN         0.1                 1   \n",
       "20240106_08_01_1_01          NaN         0.1                 1   \n",
       "\n",
       "                     prev_4_ground_condition  prev_5_horse_number  \\\n",
       "race_key                                                            \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "20240106_08_01_1_01                      NaN                  NaN   \n",
       "\n",
       "                     start_datetime  sex race_condition  prev_3_frame  \\\n",
       "race_key                                                                \n",
       "20240106_08_01_1_01    202401060950    2             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "20240106_08_01_1_01    202401060950    1             A3           NaN   \n",
       "\n",
       "                     jockey_recent_2_course_type  jockey_index  \\\n",
       "race_key                                                         \n",
       "20240106_08_01_1_01                          1.0           0.4   \n",
       "20240106_08_01_1_01                          1.0           0.6   \n",
       "20240106_08_01_1_01                          1.0           0.6   \n",
       "20240106_08_01_1_01                          1.0           0.6   \n",
       "20240106_08_01_1_01                          1.0           0.6   \n",
       "20240106_08_01_1_01                          2.0           0.2   \n",
       "20240106_08_01_1_01                          2.0           0.2   \n",
       "20240106_08_01_1_01                          2.0           0.2   \n",
       "20240106_08_01_1_01                          2.0           0.2   \n",
       "20240106_08_01_1_01                          2.0           0.2   \n",
       "\n",
       "                     jockey_place_rate  running_style  \n",
       "race_key                                               \n",
       "20240106_08_01_1_01           0.500000              3  \n",
       "20240106_08_01_1_01           0.000000              4  \n",
       "20240106_08_01_1_01           0.000000              4  \n",
       "20240106_08_01_1_01           0.000000              4  \n",
       "20240106_08_01_1_01           0.000000              4  \n",
       "20240106_08_01_1_01           0.333333              3  \n",
       "20240106_08_01_1_01           0.333333              3  \n",
       "20240106_08_01_1_01           0.333333              3  \n",
       "20240106_08_01_1_01           0.333333              3  \n",
       "20240106_08_01_1_01           0.333333              3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの基本統計\n",
    "print(\"基本統計:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 欠損値の確認\n",
    "print(\"\\n欠損値:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# 着順の分布（original_dfから確認）\n",
    "if 'rank' in original_df.columns:\n",
    "    print(\"\\n着順の分布（original_dfから）:\")\n",
    "    print(original_df['rank'].value_counts().sort_index())\n",
    "else:\n",
    "    print(\"\\n警告: original_dfにrankフィールドが見つかりません\")\n",
    "\n",
    "# データの上位50件を表示（すべての列を表示）\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"データの上位50件:\")\n",
    "print(\"=\" * 60)\n",
    "# すべての列を表示するためのオプション設定\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・検証データの分割\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備完了\n",
    "\n",
    "学習用データとテスト用データの準備が完了しました。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank列の状態: 学習=229,956件, 検証=288,988件\n"
     ]
    }
   ],
   "source": [
    "# 学習データと検証データにrankを追加（RankPredictorが学習時に必要とするため）\n",
    "# TrainingDataProcessor.process()で既に追加されている可能性があるため、確認してから追加\n",
    "train_has_rank = 'rank' in train_df.columns\n",
    "val_has_rank = 'rank' in val_df.columns\n",
    "\n",
    "if not train_has_rank or not val_has_rank:\n",
    "    # rank列が含まれていない場合のみ、original_dfから追加\n",
    "    if 'rank' in original_df.columns:\n",
    "        # インデックスがrace_keyの場合でも、安全のためmergeを使用\n",
    "        if train_df.index.name == 'race_key' and original_df.index.name == 'race_key':\n",
    "            if not train_has_rank:\n",
    "                train_df = train_df.copy()\n",
    "                train_df_index_name = train_df.index.name\n",
    "                train_df = train_df.reset_index()\n",
    "                original_df_index_name = original_df.index.name\n",
    "                original_df_with_index = original_df[['rank']].reset_index()\n",
    "                train_df = train_df.merge(\n",
    "                    original_df_with_index,\n",
    "                    left_on=train_df_index_name,\n",
    "                    right_on=original_df_index_name,\n",
    "                    how='left'\n",
    "                )\n",
    "                train_df = train_df.set_index(train_df_index_name)\n",
    "            \n",
    "            if not val_has_rank:\n",
    "                val_df = val_df.copy()\n",
    "                val_df_index_name = val_df.index.name\n",
    "                val_df = val_df.reset_index()\n",
    "                original_df_index_name = original_df.index.name\n",
    "                original_df_with_index = original_df[['rank']].reset_index()\n",
    "                val_df = val_df.merge(\n",
    "                    original_df_with_index,\n",
    "                    left_on=val_df_index_name,\n",
    "                    right_on=original_df_index_name,\n",
    "                    how='left'\n",
    "                )\n",
    "                val_df = val_df.set_index(val_df_index_name)\n",
    "        elif 'race_key' in train_df.columns and 'race_key' in original_df.columns:\n",
    "            if not train_has_rank:\n",
    "                train_df = train_df.merge(original_df[['rank']], left_on='race_key', right_on='race_key', how='left')\n",
    "            if not val_has_rank:\n",
    "                val_df = val_df.merge(original_df[['rank']], left_on='race_key', right_on='race_key', how='left')\n",
    "        else:\n",
    "            raise ValueError(\"race_keyが見つかりません。インデックスまたはカラムとして存在する必要があります。\")\n",
    "    else:\n",
    "        raise ValueError(\"original_dfにrank列が見つかりません。\")\n",
    "\n",
    "# rank列の確認（追加後）\n",
    "train_rank_count = train_df['rank'].notna().sum() if 'rank' in train_df.columns else 0\n",
    "val_rank_count = val_df['rank'].notna().sum() if 'rank' in val_df.columns else 0\n",
    "print(f\"rank列の状態: 学習={train_rank_count:,}件, 検証={val_rank_count:,}件\")\n",
    "\n",
    "if train_rank_count == 0 or val_rank_count == 0:\n",
    "    raise ValueError(f\"rank列が不足しています。学習={train_rank_count:,}件, 検証={val_rank_count:,}件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 10:39:24,219] A new study created in memory with name: no-name-d75603bc-44af-4a99-b17a-42e1217acfdc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル学習を開始します...\n",
      "（Optunaによるハイパーパラメータチューニングが実行されます）\n",
      "\n",
      "効率化設定（推奨度3まで実装済み）:\n",
      "  ✓ 早期停止: 50ラウンド（推奨度1: ★★★★★）\n",
      "  ✓ データ型最適化: 有効（推奨度2: ★★★★☆）\n",
      "  ✓ Optuna試行回数制限: 50回（推奨度3: ★★★☆☆）\n",
      "\n",
      "必要に応じて以下のパラメータを調整可能:\n",
      "  - early_stopping_rounds: 早期停止のラウンド数（デフォルト: 50）\n",
      "  - optuna_n_trials: Optunaの試行回数（デフォルト: 50）\n",
      "  - optuna_timeout: Optunaの最大実行時間（秒、デフォルト: None）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.887772:  14%|#4        | 1/7 [00:02<00:13,  2.17s/it][I 2025-11-20 10:39:26,404] Trial 0 finished with value: 0.8877721943048574 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.8877721943048574.\n",
      "feature_fraction, val_score: 0.887772:  29%|##8       | 2/7 [00:04<00:10,  2.06s/it][I 2025-11-20 10:39:28,383] Trial 1 finished with value: 0.8805695142378558 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8877721943048574.\n",
      "feature_fraction, val_score: 0.887772:  43%|####2     | 3/7 [00:05<00:07,  1.92s/it][I 2025-11-20 10:39:30,143] Trial 2 finished with value: 0.8554438860971523 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8877721943048574.\n",
      "feature_fraction, val_score: 0.887772:  57%|#####7    | 4/7 [00:08<00:06,  2.18s/it][I 2025-11-20 10:39:32,718] Trial 3 finished with value: 0.8860253649198372 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.8877721943048574.\n",
      "feature_fraction, val_score: 0.892510:  71%|#######1  | 5/7 [00:10<00:04,  2.19s/it][I 2025-11-20 10:39:34,931] Trial 4 finished with value: 0.8925101698971043 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.8925101698971043.\n",
      "feature_fraction, val_score: 0.892510:  86%|########5 | 6/7 [00:12<00:02,  2.04s/it][I 2025-11-20 10:39:36,684] Trial 5 finished with value: 0.8513759272553241 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.8925101698971043.\n",
      "feature_fraction, val_score: 0.892510: 100%|##########| 7/7 [00:14<00:00,  1.93s/it][I 2025-11-20 10:39:38,373] Trial 6 finished with value: 0.8358458961474037 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.8925101698971043.\n",
      "feature_fraction, val_score: 0.892510: 100%|##########| 7/7 [00:14<00:00,  2.02s/it]\n",
      "num_leaves, val_score: 0.892510:   5%|5         | 1/20 [00:04<01:19,  4.16s/it][I 2025-11-20 10:39:42,550] Trial 7 finished with value: 0.8583632447954055 and parameters: {'num_leaves': 179}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  10%|#         | 2/20 [00:06<00:54,  3.01s/it][I 2025-11-20 10:39:44,760] Trial 8 finished with value: 0.8442928930366115 and parameters: {'num_leaves': 74}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  15%|#5        | 3/20 [00:08<00:45,  2.66s/it][I 2025-11-20 10:39:47,007] Trial 9 finished with value: 0.8493658770040678 and parameters: {'num_leaves': 59}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  20%|##        | 4/20 [00:13<00:56,  3.50s/it][I 2025-11-20 10:39:51,787] Trial 10 finished with value: 0.8212491026561377 and parameters: {'num_leaves': 253}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  25%|##5       | 5/20 [00:15<00:47,  3.15s/it][I 2025-11-20 10:39:54,316] Trial 11 finished with value: 0.8740607800909307 and parameters: {'num_leaves': 6}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  30%|###       | 6/20 [00:19<00:45,  3.24s/it][I 2025-11-20 10:39:57,723] Trial 12 finished with value: 0.8336683417085426 and parameters: {'num_leaves': 154}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  35%|###5      | 7/20 [00:23<00:47,  3.63s/it][I 2025-11-20 10:40:02,148] Trial 13 finished with value: 0.8238095238095237 and parameters: {'num_leaves': 238}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  40%|####      | 8/20 [00:26<00:39,  3.32s/it][I 2025-11-20 10:40:04,809] Trial 14 finished with value: 0.8435032304379038 and parameters: {'num_leaves': 109}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  45%|####5     | 9/20 [00:29<00:35,  3.21s/it][I 2025-11-20 10:40:07,789] Trial 15 finished with value: 0.8541756401052883 and parameters: {'num_leaves': 3}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  50%|#####     | 10/20 [00:33<00:34,  3.49s/it][I 2025-11-20 10:40:11,888] Trial 16 finished with value: 0.8280928451782721 and parameters: {'num_leaves': 207}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  55%|#####5    | 11/20 [00:36<00:29,  3.32s/it][I 2025-11-20 10:40:14,818] Trial 17 finished with value: 0.8464704474754724 and parameters: {'num_leaves': 120}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  60%|######    | 12/20 [00:38<00:24,  3.04s/it][I 2025-11-20 10:40:17,238] Trial 18 finished with value: 0.8756401052883465 and parameters: {'num_leaves': 56}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  65%|######5   | 13/20 [00:43<00:23,  3.40s/it][I 2025-11-20 10:40:21,472] Trial 19 finished with value: 0.8502751854510647 and parameters: {'num_leaves': 197}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  70%|#######   | 14/20 [00:46<00:20,  3.41s/it][I 2025-11-20 10:40:24,913] Trial 20 finished with value: 0.844867193108399 and parameters: {'num_leaves': 152}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  75%|#######5  | 15/20 [00:48<00:15,  3.11s/it][I 2025-11-20 10:40:27,302] Trial 21 finished with value: 0.8632926537449149 and parameters: {'num_leaves': 84}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  80%|########  | 16/20 [00:50<00:10,  2.73s/it][I 2025-11-20 10:40:29,147] Trial 22 finished with value: 0.8850442689638668 and parameters: {'num_leaves': 30}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  85%|########5 | 17/20 [00:54<00:08,  2.91s/it][I 2025-11-20 10:40:32,487] Trial 23 finished with value: 0.8452261306532663 and parameters: {'num_leaves': 150}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  90%|######### | 18/20 [00:58<00:06,  3.31s/it][I 2025-11-20 10:40:36,714] Trial 24 finished with value: 0.8197894233070111 and parameters: {'num_leaves': 224}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510:  95%|#########5| 19/20 [01:00<00:03,  3.08s/it][I 2025-11-20 10:40:39,279] Trial 25 finished with value: 0.8407274467575975 and parameters: {'num_leaves': 101}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510: 100%|##########| 20/20 [01:04<00:00,  3.28s/it][I 2025-11-20 10:40:43,020] Trial 26 finished with value: 0.8337162000478582 and parameters: {'num_leaves': 177}. Best is trial 4 with value: 0.8925101698971043.\n",
      "num_leaves, val_score: 0.892510: 100%|##########| 20/20 [01:04<00:00,  3.23s/it]\n",
      "bagging, val_score: 0.892510:  10%|#         | 1/10 [00:01<00:16,  1.88s/it][I 2025-11-20 10:40:44,915] Trial 27 finished with value: 0.8802584350323042 and parameters: {'bagging_fraction': 0.8290966202970953, 'bagging_freq': 5}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  20%|##        | 2/10 [00:03<00:14,  1.84s/it][I 2025-11-20 10:40:46,727] Trial 28 finished with value: 0.8631969370662839 and parameters: {'bagging_fraction': 0.45076676214295547, 'bagging_freq': 1}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  30%|###       | 3/10 [00:05<00:14,  2.01s/it][I 2025-11-20 10:40:48,931] Trial 29 finished with value: 0.8831777937305575 and parameters: {'bagging_fraction': 0.9928650935900654, 'bagging_freq': 7}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  40%|####      | 4/10 [00:07<00:11,  2.00s/it][I 2025-11-20 10:40:50,908] Trial 30 finished with value: 0.8773630055037088 and parameters: {'bagging_fraction': 0.4023028865402567, 'bagging_freq': 2}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  50%|#####     | 5/10 [00:09<00:10,  2.02s/it][I 2025-11-20 10:40:52,957] Trial 31 finished with value: 0.8793730557549653 and parameters: {'bagging_fraction': 0.6455902284260232, 'bagging_freq': 4}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  60%|######    | 6/10 [00:11<00:07,  1.98s/it][I 2025-11-20 10:40:54,863] Trial 32 finished with value: 0.8808805934434075 and parameters: {'bagging_fraction': 0.645061822767833, 'bagging_freq': 7}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  70%|#######   | 7/10 [00:13<00:06,  2.03s/it][I 2025-11-20 10:40:57,012] Trial 33 finished with value: 0.8854271356783919 and parameters: {'bagging_fraction': 0.9877395996139684, 'bagging_freq': 4}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  80%|########  | 8/10 [00:16<00:04,  2.08s/it][I 2025-11-20 10:40:59,200] Trial 34 finished with value: 0.8865996649916247 and parameters: {'bagging_fraction': 0.9980686708235695, 'bagging_freq': 4}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510:  90%|######### | 9/10 [00:18<00:02,  2.06s/it][I 2025-11-20 10:41:01,220] Trial 35 finished with value: 0.8808805934434075 and parameters: {'bagging_fraction': 0.8121782567057809, 'bagging_freq': 3}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510: 100%|##########| 10/10 [00:20<00:00,  2.06s/it][I 2025-11-20 10:41:03,281] Trial 36 finished with value: 0.8782962431203635 and parameters: {'bagging_fraction': 0.8351883670169854, 'bagging_freq': 5}. Best is trial 4 with value: 0.8925101698971043.\n",
      "bagging, val_score: 0.892510: 100%|##########| 10/10 [00:20<00:00,  2.03s/it]\n",
      "feature_fraction_stage2, val_score: 0.892510:  17%|#6        | 1/6 [00:01<00:09,  1.85s/it][I 2025-11-20 10:41:05,144] Trial 37 finished with value: 0.8793012682459919 and parameters: {'feature_fraction': 0.616}. Best is trial 4 with value: 0.8925101698971043.\n",
      "feature_fraction_stage2, val_score: 0.892510:  33%|###3      | 2/6 [00:03<00:07,  1.94s/it][I 2025-11-20 10:41:07,154] Trial 38 finished with value: 0.8862407274467575 and parameters: {'feature_fraction': 0.584}. Best is trial 4 with value: 0.8925101698971043.\n",
      "feature_fraction_stage2, val_score: 0.893084:  50%|#####     | 3/6 [00:05<00:06,  2.01s/it][I 2025-11-20 10:41:09,242] Trial 39 finished with value: 0.8930844699688918 and parameters: {'feature_fraction': 0.52}. Best is trial 39 with value: 0.8930844699688918.\n",
      "feature_fraction_stage2, val_score: 0.893084:  67%|######6   | 4/6 [00:07<00:03,  1.96s/it][I 2025-11-20 10:41:11,109] Trial 40 finished with value: 0.8796602057908589 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 39 with value: 0.8930844699688918.\n",
      "feature_fraction_stage2, val_score: 0.893084:  83%|########3 | 5/6 [00:09<00:01,  1.95s/it][I 2025-11-20 10:41:13,051] Trial 41 finished with value: 0.8799952141660683 and parameters: {'feature_fraction': 0.552}. Best is trial 39 with value: 0.8930844699688918.\n",
      "feature_fraction_stage2, val_score: 0.893084: 100%|##########| 6/6 [00:11<00:00,  1.88s/it][I 2025-11-20 10:41:14,797] Trial 42 finished with value: 0.8791576932280448 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 39 with value: 0.8930844699688918.\n",
      "feature_fraction_stage2, val_score: 0.893084: 100%|##########| 6/6 [00:11<00:00,  1.92s/it]\n",
      "regularization_factors, val_score: 0.893084:   5%|5         | 1/20 [00:02<00:40,  2.16s/it][I 2025-11-20 10:41:16,967] Trial 43 finished with value: 0.8862885857860732 and parameters: {'lambda_l1': 0.02731802539694545, 'lambda_l2': 0.003999515238366855}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  10%|#         | 2/20 [00:04<00:38,  2.14s/it][I 2025-11-20 10:41:19,097] Trial 44 finished with value: 0.8872696817420433 and parameters: {'lambda_l1': 0.03256973201079027, 'lambda_l2': 0.003635128444845859}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  15%|#5        | 3/20 [00:06<00:36,  2.15s/it][I 2025-11-20 10:41:21,266] Trial 45 finished with value: 0.8771476429767887 and parameters: {'lambda_l1': 7.815853382032231, 'lambda_l2': 1.0133206008201692e-07}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  20%|##        | 4/20 [00:08<00:35,  2.20s/it][I 2025-11-20 10:41:23,533] Trial 46 finished with value: 0.8855707106963386 and parameters: {'lambda_l1': 1.2779069437179898e-07, 'lambda_l2': 3.0571918482672977}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  25%|##5       | 5/20 [00:10<00:32,  2.16s/it][I 2025-11-20 10:41:25,612] Trial 47 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 0.00028899557813988623, 'lambda_l2': 0.00024389311996032747}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  30%|###       | 6/20 [00:12<00:29,  2.14s/it][I 2025-11-20 10:41:27,720] Trial 48 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 0.0002801474934030854, 'lambda_l2': 0.0003266276245084997}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  35%|###5      | 7/20 [00:15<00:28,  2.17s/it][I 2025-11-20 10:41:29,946] Trial 49 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 2.115730169189378e-05, 'lambda_l2': 8.39062008851502e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  40%|####      | 8/20 [00:17<00:26,  2.17s/it][I 2025-11-20 10:41:32,133] Trial 50 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 1.2040905434189674e-05, 'lambda_l2': 5.556736775278623e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  45%|####5     | 9/20 [00:19<00:23,  2.18s/it][I 2025-11-20 10:41:34,331] Trial 51 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 1.5810105152768304e-05, 'lambda_l2': 4.429302902540447e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  50%|#####     | 10/20 [00:21<00:21,  2.18s/it][I 2025-11-20 10:41:36,521] Trial 52 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 1.5882217048673307e-05, 'lambda_l2': 4.439198947316502e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  55%|#####5    | 11/20 [00:23<00:19,  2.17s/it][I 2025-11-20 10:41:38,665] Trial 53 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 3.4012233726389526e-05, 'lambda_l2': 1.7953036058216674e-05}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  60%|######    | 12/20 [00:26<00:17,  2.17s/it][I 2025-11-20 10:41:40,846] Trial 54 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 4.041789301144748e-05, 'lambda_l2': 2.4074854765673437e-05}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  65%|######5   | 13/20 [00:28<00:14,  2.14s/it][I 2025-11-20 10:41:42,901] Trial 55 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 3.5607355331266857e-06, 'lambda_l2': 0.00014773468667275924}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  70%|#######   | 14/20 [00:30<00:12,  2.10s/it][I 2025-11-20 10:41:44,926] Trial 56 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 0.0007414195323187644, 'lambda_l2': 6.817526652351418e-07}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  75%|#######5  | 15/20 [00:32<00:10,  2.10s/it][I 2025-11-20 10:41:47,002] Trial 57 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 0.00038735771190774674, 'lambda_l2': 0.0010109528417088598}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  80%|########  | 16/20 [00:34<00:08,  2.09s/it][I 2025-11-20 10:41:49,075] Trial 58 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 2.136782226965434e-06, 'lambda_l2': 3.2630591204464923e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  85%|########5 | 17/20 [00:36<00:06,  2.14s/it][I 2025-11-20 10:41:51,325] Trial 59 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 0.0008091812011074787, 'lambda_l2': 0.00011019000434927448}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  90%|######### | 18/20 [00:38<00:04,  2.15s/it][I 2025-11-20 10:41:53,511] Trial 60 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 6.798979345568019e-05, 'lambda_l2': 5.000801292648869e-07}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084:  95%|#########5| 19/20 [00:40<00:02,  2.17s/it][I 2025-11-20 10:41:55,725] Trial 61 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 4.557703457244262e-06, 'lambda_l2': 7.098768709615338e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084: 100%|##########| 20/20 [00:43<00:00,  2.16s/it][I 2025-11-20 10:41:57,873] Trial 62 finished with value: 0.8930844699688918 and parameters: {'lambda_l1': 1.9210648093676948e-05, 'lambda_l2': 4.39917008087575e-06}. Best is trial 39 with value: 0.8930844699688918.\n",
      "regularization_factors, val_score: 0.893084: 100%|##########| 20/20 [00:43<00:00,  2.15s/it]\n",
      "min_child_samples, val_score: 0.893084:  20%|##        | 1/5 [00:02<00:08,  2.00s/it][I 2025-11-20 10:41:59,887] Trial 63 finished with value: 0.8845417564010527 and parameters: {'min_child_samples': 50}. Best is trial 39 with value: 0.8930844699688918.\n",
      "min_child_samples, val_score: 0.893396:  40%|####      | 2/5 [00:04<00:06,  2.04s/it][I 2025-11-20 10:42:01,957] Trial 64 finished with value: 0.8933955491744435 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.8933955491744435.\n",
      "min_child_samples, val_score: 0.894712:  60%|######    | 3/5 [00:06<00:04,  2.09s/it][I 2025-11-20 10:42:04,093] Trial 65 finished with value: 0.8947116535056233 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.8947116535056233.\n",
      "min_child_samples, val_score: 0.894712:  80%|########  | 4/5 [00:08<00:02,  2.05s/it][I 2025-11-20 10:42:06,079] Trial 66 finished with value: 0.8813113184972481 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.8947116535056233.\n",
      "min_child_samples, val_score: 0.894712: 100%|##########| 5/5 [00:10<00:00,  2.07s/it][I 2025-11-20 10:42:08,182] Trial 67 finished with value: 0.8947116535056233 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.8947116535056233.\n",
      "min_child_samples, val_score: 0.894712: 100%|##########| 5/5 [00:10<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適パラメータ: {'objective': 'lambdarank', 'metric': 'ndcg', 'ndcg_eval_at': [1, 2, 3], 'boosting_type': 'gbdt', 'random_state': 0, 'num_leaves': 31, 'deterministic': True, 'force_row_wise': True, 'num_threads': 12, 'max_bin': 255, 'verbose': -1, 'early_stopping_rounds': 50, 'feature_pre_filter': False, 'min_child_samples': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'feature_fraction': 0.52, 'bagging_fraction': 1.0, 'bagging_freq': 0}\n",
      "\n",
      "モデル学習完了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RankPredictorのインスタンスを作成\n",
    "rank_predictor = RankPredictor(train_df, val_df)\n",
    "\n",
    "print(\"モデル学習を開始します...\")\n",
    "print(\"（Optunaによるハイパーパラメータチューニングが実行されます）\")\n",
    "print(\"\\n効率化設定（推奨度3まで実装済み）:\")\n",
    "print(\"  ✓ 早期停止: 50ラウンド（推奨度1: ★★★★★）\")\n",
    "print(\"  ✓ データ型最適化: 有効（推奨度2: ★★★★☆）\")\n",
    "print(\"  ✓ Optuna試行回数制限: 50回（推奨度3: ★★★☆☆）\")\n",
    "print(\"\\n必要に応じて以下のパラメータを調整可能:\")\n",
    "print(\"  - early_stopping_rounds: 早期停止のラウンド数（デフォルト: 50）\")\n",
    "print(\"  - optuna_n_trials: Optunaの試行回数（デフォルト: 50）\")\n",
    "print(\"  - optuna_timeout: Optunaの最大実行時間（秒、デフォルト: None）\")\n",
    "\n",
    "# モデルを学習（推奨度3までの効率化が有効）\n",
    "# 例: より多くの試行回数が必要な場合\n",
    "# model = rank_predictor.train(optuna_n_trials=100)\n",
    "model = rank_predictor.train()\n",
    "\n",
    "print(\"\\nモデル学習完了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルを保存しました: ../models/rank_model_202511201035_v1.txt\n"
     ]
    }
   ],
   "source": [
    "# モデルを保存\n",
    "model.save_model(str(MODEL_PATH))\n",
    "print(f\"モデルを保存しました: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データで予測を実行します...\n",
      "[DEBUG] val_dfにrank列が含まれているか: True\n",
      "[DEBUG] val_dfのrank列の有効値数: 288,988件 / 291,434件\n",
      "[DEBUG] val_dfのインデックス名: race_key\n",
      "[DEBUG] val_dfのカラム数: 115\n",
      "予測完了: 291434件\n",
      "\n",
      "予測結果のサンプル:\n",
      "   predict             race_key stable  prev_5_time  prev_1_frame  prize_2  \\\n",
      "0    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "1    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "2    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "3    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "4    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "5    -2.08  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "6    -3.92  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "7    -3.25  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "8    -3.89  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "9    -3.89  20240601_08_04_1_01     栗東          NaN           NaN      220   \n",
      "\n",
      "   weight_type  prev_1_num_horses  prev_3_distance  jockey_recent_3_time  \\\n",
      "0            3               16.0           1200.0                1126.0   \n",
      "1            3               16.0           1200.0                1126.0   \n",
      "2            3               16.0           1200.0                1126.0   \n",
      "3            3               16.0           1200.0                1126.0   \n",
      "4            3               16.0           1200.0                1126.0   \n",
      "5            3               16.0           1200.0                1126.0   \n",
      "6            3               16.0              NaN                2133.0   \n",
      "7            3               16.0           1800.0                1134.0   \n",
      "8            3               15.0              NaN                1574.0   \n",
      "9            3               15.0              NaN                1574.0   \n",
      "\n",
      "   round  prev_2_distance  prev_3_time  horse_weight  jockey_recent_2_time  \\\n",
      "0      4           1400.0       1146.0         478.0                1257.0   \n",
      "1      4           1400.0       1146.0         478.0                1257.0   \n",
      "2      4           1400.0       1146.0         478.0                1257.0   \n",
      "3      4           1400.0       1146.0         478.0                1257.0   \n",
      "4      4           1400.0       1146.0         478.0                1257.0   \n",
      "5      4           1400.0       1146.0         478.0                1257.0   \n",
      "6      4              NaN          NaN         458.0                1461.0   \n",
      "7      4           1800.0       1504.0         500.0                1568.0   \n",
      "8      4           1600.0          NaN         412.0                1539.0   \n",
      "9      4           1600.0          NaN         412.0                1539.0   \n",
      "\n",
      "   horse_avg_rank  trainer_place_rate  distance_aptitude  prev_3_num_horses  \\\n",
      "0        5.750000            0.216000                  5               16.0   \n",
      "1        5.750000            0.216000                  5               16.0   \n",
      "2        5.750000            0.216000                  5               16.0   \n",
      "3        5.750000            0.216000                  5               16.0   \n",
      "4        5.750000            0.216000                  5               16.0   \n",
      "5        5.750000            0.216000                  5               16.0   \n",
      "6       15.000000            0.211864                  1                NaN   \n",
      "7        8.000000            0.323529                  2               12.0   \n",
      "8        9.666667            0.339806                  0                NaN   \n",
      "9        9.666667            0.339806                  0                NaN   \n",
      "\n",
      "   jockey_recent_3_ground_condition  prev_4_course_type  paddock_index  \\\n",
      "0                              20.0                 NaN            1.9   \n",
      "1                              20.0                 NaN            1.9   \n",
      "2                              20.0                 NaN            1.9   \n",
      "3                              20.0                 NaN            1.9   \n",
      "4                              20.0                 NaN            1.9   \n",
      "5                              20.0                 NaN            1.9   \n",
      "6                              11.0                 NaN            0.0   \n",
      "7                              20.0                 1.0            0.0   \n",
      "8                              20.0                 NaN            0.0   \n",
      "9                              20.0                 NaN            0.0   \n",
      "\n",
      "   prev_3_rank  prev_1_distance  jockey_recent_1_distance  prev_2_race_num  \\\n",
      "0          5.0           1400.0                    1200.0              NaN   \n",
      "1          5.0           1400.0                    1200.0              NaN   \n",
      "2          5.0           1400.0                    1200.0              NaN   \n",
      "3          5.0           1400.0                    1200.0              NaN   \n",
      "4          5.0           1400.0                    1200.0              NaN   \n",
      "5          5.0           1400.0                    1200.0              NaN   \n",
      "6          NaN           1200.0                    2000.0              NaN   \n",
      "7          6.0           1800.0                    1800.0              NaN   \n",
      "8          NaN           1600.0                    2200.0              NaN   \n",
      "9          NaN           1600.0                    2200.0              NaN   \n",
      "\n",
      "   jockey_recent_2_race_num  prev_5_race_num  prev_4_rank  jockey_race_count  \\\n",
      "0                       1.0              NaN          NaN                347   \n",
      "1                       1.0              NaN          NaN                347   \n",
      "2                       1.0              NaN          NaN                347   \n",
      "3                       1.0              NaN          NaN                347   \n",
      "4                       1.0              NaN          NaN                347   \n",
      "5                       1.0              NaN          NaN                347   \n",
      "6                       8.0              NaN          NaN                172   \n",
      "7                       2.0              NaN          4.0                324   \n",
      "8                       6.0              NaN          NaN                144   \n",
      "9                       6.0              NaN          NaN                144   \n",
      "\n",
      "   prev_5_course_type race_grade  weight_aptitude  jockey_win_rate  \\\n",
      "0                 NaN                         3.0         0.121037   \n",
      "1                 NaN                         3.0         0.121037   \n",
      "2                 NaN                         3.0         0.121037   \n",
      "3                 NaN                         3.0         0.121037   \n",
      "4                 NaN                         3.0         0.121037   \n",
      "5                 NaN                         3.0         0.121037   \n",
      "6                 NaN                         2.0         0.023256   \n",
      "7                 NaN                         2.0         0.033951   \n",
      "8                 NaN                         2.0         0.027778   \n",
      "9                 NaN                         2.0         0.027778   \n",
      "\n",
      "   prev_2_frame  prev_1_race_num  trainer_avg_rank  jockey_id  jockey_weight  \\\n",
      "0           NaN              NaN          7.816000      10578            550   \n",
      "1           NaN              NaN          7.816000      10578            550   \n",
      "2           NaN              NaN          7.816000      10578            550   \n",
      "3           NaN              NaN          7.816000      10578            550   \n",
      "4           NaN              NaN          7.816000      10578            550   \n",
      "5           NaN              NaN          7.816000      10578            550   \n",
      "6           NaN              NaN          7.033898      10436            550   \n",
      "7           NaN              NaN          6.632353      10419            550   \n",
      "8           NaN              NaN          6.281553      10545            550   \n",
      "9           NaN              NaN          6.281553      10545            550   \n",
      "\n",
      "   prev_4_num_horses  prev_4_time  jockey_recent_2_ground_condition  \\\n",
      "0                NaN          NaN                              20.0   \n",
      "1                NaN          NaN                              20.0   \n",
      "2                NaN          NaN                              20.0   \n",
      "3                NaN          NaN                              20.0   \n",
      "4                NaN          NaN                              20.0   \n",
      "5                NaN          NaN                              20.0   \n",
      "6                NaN          NaN                              11.0   \n",
      "7               14.0       1524.0                              20.0   \n",
      "8                NaN          NaN                              20.0   \n",
      "9                NaN          NaN                              20.0   \n",
      "\n",
      "   prev_5_rank  day  total_index  trainer_win_rate  prev_2_horse_number  \\\n",
      "0          NaN  1.0         30.4          0.072000                  NaN   \n",
      "1          NaN  1.0         30.4          0.072000                  NaN   \n",
      "2          NaN  1.0         30.4          0.072000                  NaN   \n",
      "3          NaN  1.0         30.4          0.072000                  NaN   \n",
      "4          NaN  1.0         30.4          0.072000                  NaN   \n",
      "5          NaN  1.0         30.4          0.072000                  NaN   \n",
      "6          NaN  1.0         13.2          0.076271                  NaN   \n",
      "7          NaN  1.0         20.5          0.132353                  NaN   \n",
      "8          NaN  1.0         14.1          0.145631                  NaN   \n",
      "9          NaN  1.0         14.1          0.145631                  NaN   \n",
      "\n",
      "        time  jockey_recent_1_race_num  jockey_recent_3_rank  \\\n",
      "0  85.699997                       9.0                   2.0   \n",
      "1  85.699997                       9.0                   2.0   \n",
      "2  85.699997                       9.0                   2.0   \n",
      "3  85.699997                       9.0                   2.0   \n",
      "4  85.699997                       9.0                   2.0   \n",
      "5  85.699997                       9.0                   2.0   \n",
      "6  88.099998                      11.0                   4.0   \n",
      "7  85.599998                       6.0                   8.0   \n",
      "8  86.000000                       7.0                  12.0   \n",
      "9  86.000000                       7.0                  12.0   \n",
      "\n",
      "   prev_2_course_type  trainer_id  prev_4_distance  prev_1_horse_number  \\\n",
      "0                 2.0       10432              NaN                  NaN   \n",
      "1                 2.0       10432              NaN                  NaN   \n",
      "2                 2.0       10432              NaN                  NaN   \n",
      "3                 2.0       10432              NaN                  NaN   \n",
      "4                 2.0       10432              NaN                  NaN   \n",
      "5                 2.0       10432              NaN                  NaN   \n",
      "6                 NaN       10420              NaN                  NaN   \n",
      "7                 1.0       10339           1800.0                  NaN   \n",
      "8                 1.0       10492              NaN                  NaN   \n",
      "9                 1.0       10492              NaN                  NaN   \n",
      "\n",
      "   prev_5_num_horses  race_mark  jockey_recent_1_course_type  \\\n",
      "0                NaN         22                          2.0   \n",
      "1                NaN         22                          2.0   \n",
      "2                NaN         22                          2.0   \n",
      "3                NaN         22                          2.0   \n",
      "4                NaN         22                          2.0   \n",
      "5                NaN         22                          2.0   \n",
      "6                NaN         22                          1.0   \n",
      "7                NaN         22                          2.0   \n",
      "8                NaN         22                          1.0   \n",
      "9                NaN         22                          1.0   \n",
      "\n",
      "   jockey_recent_3_num_horses  stable_index  prev_2_ground_condition  \\\n",
      "0                        16.0          -5.1                     10.0   \n",
      "1                        16.0          -5.1                     10.0   \n",
      "2                        16.0          -5.1                     10.0   \n",
      "3                        16.0          -5.1                     10.0   \n",
      "4                        16.0          -5.1                     10.0   \n",
      "5                        16.0          -5.1                     10.0   \n",
      "6                         9.0         -10.5                      NaN   \n",
      "7                        16.0         -13.0                     20.0   \n",
      "8                        16.0         -10.2                     11.0   \n",
      "9                        16.0         -10.2                     11.0   \n",
      "\n",
      "   jockey_recent_1_num_horses  jockey_recent_3_distance dirt_aptitude  \\\n",
      "0                        16.0                    1200.0             2   \n",
      "1                        16.0                    1200.0             2   \n",
      "2                        16.0                    1200.0             2   \n",
      "3                        16.0                    1200.0             2   \n",
      "4                        16.0                    1200.0             2   \n",
      "5                        16.0                    1200.0             2   \n",
      "6                        14.0                    2200.0             3   \n",
      "7                        13.0                    1200.0             3   \n",
      "8                         9.0                    1800.0                 \n",
      "9                         9.0                    1800.0                 \n",
      "\n",
      "   jockey_recent_3_race_num  horse_place_rate  prev_3_ground_condition  \\\n",
      "0                       3.0              0.25                     10.0   \n",
      "1                       3.0              0.25                     10.0   \n",
      "2                       3.0              0.25                     10.0   \n",
      "3                       3.0              0.25                     10.0   \n",
      "4                       3.0              0.25                     10.0   \n",
      "5                       3.0              0.25                     10.0   \n",
      "6                       7.0              0.00                      NaN   \n",
      "7                       3.0              0.00                     11.0   \n",
      "8                       2.0              0.00                      NaN   \n",
      "9                       2.0              0.00                      NaN   \n",
      "\n",
      "   horse_win_rate  jockey_recent_2_num_horses  place  prev_5_ground_condition  \\\n",
      "0             0.0                        16.0      8                      NaN   \n",
      "1             0.0                        16.0      8                      NaN   \n",
      "2             0.0                        16.0      8                      NaN   \n",
      "3             0.0                        16.0      8                      NaN   \n",
      "4             0.0                        16.0      8                      NaN   \n",
      "5             0.0                        16.0      8                      NaN   \n",
      "6             0.0                         7.0      8                      NaN   \n",
      "7             0.0                        16.0      8                      NaN   \n",
      "8             0.0                        13.0      8                      NaN   \n",
      "9             0.0                        13.0      8                      NaN   \n",
      "\n",
      "   prev_1_course_type  training_index  course_setting  prev_1_rank  \\\n",
      "0                 2.0            -0.5               1         11.0   \n",
      "1                 2.0            -0.5               1         11.0   \n",
      "2                 2.0            -0.5               1         11.0   \n",
      "3                 2.0            -0.5               1         11.0   \n",
      "4                 2.0            -0.5               1         11.0   \n",
      "5                 2.0            -0.5               1         11.0   \n",
      "6                 2.0           -11.2               1         15.0   \n",
      "7                 2.0            -6.6               1         14.0   \n",
      "8                 1.0           -11.2               1          9.0   \n",
      "9                 1.0           -11.2               1          9.0   \n",
      "\n",
      "   jockey_recent_3_course_type  race_class  prev_4_horse_number  prev_4_frame  \\\n",
      "0                          2.0          12                  NaN           NaN   \n",
      "1                          2.0          12                  NaN           NaN   \n",
      "2                          2.0          12                  NaN           NaN   \n",
      "3                          2.0          12                  NaN           NaN   \n",
      "4                          2.0          12                  NaN           NaN   \n",
      "5                          2.0          12                  NaN           NaN   \n",
      "6                          1.0          12                  NaN           NaN   \n",
      "7                          2.0          12                  NaN           NaN   \n",
      "8                          2.0          12                  NaN           NaN   \n",
      "9                          2.0          12                  NaN           NaN   \n",
      "\n",
      "   prev_2_rank  age  jockey_recent_2_distance  \\\n",
      "0          2.0    3                    1400.0   \n",
      "1          2.0    3                    1400.0   \n",
      "2          2.0    3                    1400.0   \n",
      "3          2.0    3                    1400.0   \n",
      "4          2.0    3                    1400.0   \n",
      "5          2.0    3                    1400.0   \n",
      "6          NaN    3                    1800.0   \n",
      "7         12.0    3                    1800.0   \n",
      "8         12.0    3                    1800.0   \n",
      "9         12.0    3                    1800.0   \n",
      "\n",
      "   jockey_recent_1_ground_condition  jockey_recent_1_time  prev_2_num_horses  \\\n",
      "0                              20.0                1123.0               15.0   \n",
      "1                              20.0                1123.0               15.0   \n",
      "2                              20.0                1123.0               15.0   \n",
      "3                              20.0                1123.0               15.0   \n",
      "4                              20.0                1123.0               15.0   \n",
      "5                              20.0                1123.0               15.0   \n",
      "6                              11.0                1593.0                NaN   \n",
      "7                              20.0                1541.0               16.0   \n",
      "8                              11.0                2138.0               14.0   \n",
      "9                              11.0                2138.0               14.0   \n",
      "\n",
      "   race_number  prev_3_course_type  horse_id  prize_3 turf_aptitude  \\\n",
      "0            1                 2.0  21105621      140                 \n",
      "1            1                 2.0  21105621      140                 \n",
      "2            1                 2.0  21105621      140                 \n",
      "3            1                 2.0  21105621      140                 \n",
      "4            1                 2.0  21105621      140                 \n",
      "5            1                 2.0  21105621      140                 \n",
      "6            1                 NaN  21103655      140                 \n",
      "7            1                 1.0  21100526      140             3   \n",
      "8            1                 NaN  21105468      140             3   \n",
      "9            1                 NaN  21105468      140             3   \n",
      "\n",
      "   prev_1_time  prev_3_race_num  trainer_race_count  prev_1_ground_condition  \\\n",
      "0       1298.0              NaN                 125                     20.0   \n",
      "1       1298.0              NaN                 125                     20.0   \n",
      "2       1298.0              NaN                 125                     20.0   \n",
      "3       1298.0              NaN                 125                     20.0   \n",
      "4       1298.0              NaN                 125                     20.0   \n",
      "5       1298.0              NaN                 125                     20.0   \n",
      "6       1170.0              NaN                 118                     10.0   \n",
      "7       1584.0              NaN                 136                     10.0   \n",
      "8       1369.0              NaN                 103                     11.0   \n",
      "9       1369.0              NaN                 103                     11.0   \n",
      "\n",
      "   jockey_recent_2_rank  prev_3_horse_number  prize_1  prev_5_distance  \\\n",
      "0                   5.0                  NaN      550              NaN   \n",
      "1                   5.0                  NaN      550              NaN   \n",
      "2                   5.0                  NaN      550              NaN   \n",
      "3                   5.0                  NaN      550              NaN   \n",
      "4                   5.0                  NaN      550              NaN   \n",
      "5                   5.0                  NaN      550              NaN   \n",
      "6                   3.0                  NaN      550              NaN   \n",
      "7                  11.0                  NaN      550              NaN   \n",
      "8                   7.0                  NaN      550              NaN   \n",
      "9                   7.0                  NaN      550              NaN   \n",
      "\n",
      "   jockey_avg_rank  jockey_recent_1_rank  prev_4_race_num  prev_5_frame  \\\n",
      "0         6.524496                  13.0              NaN           NaN   \n",
      "1         6.524496                  13.0              NaN           NaN   \n",
      "2         6.524496                  13.0              NaN           NaN   \n",
      "3         6.524496                  13.0              NaN           NaN   \n",
      "4         6.524496                  13.0              NaN           NaN   \n",
      "5         6.524496                  13.0              NaN           NaN   \n",
      "6         9.011628                  13.0              NaN           NaN   \n",
      "7         7.620370                   8.0              NaN           NaN   \n",
      "8         8.833333                   7.0              NaN           NaN   \n",
      "9         8.833333                   7.0              NaN           NaN   \n",
      "\n",
      "   weather  horse_weight_diff  rank  prev_2_time  info_index  \\\n",
      "0      1.0                0.0   5.0       1266.0         0.0   \n",
      "1      1.0                0.0   5.0       1266.0         0.0   \n",
      "2      1.0                0.0   5.0       1266.0         0.0   \n",
      "3      1.0                0.0   5.0       1266.0         0.0   \n",
      "4      1.0                0.0   5.0       1266.0         0.0   \n",
      "5      1.0                0.0   5.0       1266.0         0.0   \n",
      "6      1.0               26.0  15.0          NaN        -1.0   \n",
      "7      1.0                NaN   4.0       1529.0         0.0   \n",
      "8      1.0                NaN   8.0       1379.0        -1.0   \n",
      "9      1.0                NaN   8.0       1379.0        -1.0   \n",
      "\n",
      "   horse_race_count  prev_4_ground_condition  prev_5_horse_number  \\\n",
      "0                 4                      NaN                  NaN   \n",
      "1                 4                      NaN                  NaN   \n",
      "2                 4                      NaN                  NaN   \n",
      "3                 4                      NaN                  NaN   \n",
      "4                 4                      NaN                  NaN   \n",
      "5                 4                      NaN                  NaN   \n",
      "6                 2                      NaN                  NaN   \n",
      "7                 5                     31.0                  NaN   \n",
      "8                 3                      NaN                  NaN   \n",
      "9                 3                      NaN                  NaN   \n",
      "\n",
      "   start_datetime  sex race_condition  prev_3_frame  \\\n",
      "0    202406010950    2             A3           NaN   \n",
      "1    202406010950    2             A3           NaN   \n",
      "2    202406010950    2             A3           NaN   \n",
      "3    202406010950    2             A3           NaN   \n",
      "4    202406010950    2             A3           NaN   \n",
      "5    202406010950    2             A3           NaN   \n",
      "6    202406010950    2             A3           NaN   \n",
      "7    202406010950    2             A3           NaN   \n",
      "8    202406010950    2             A3           NaN   \n",
      "9    202406010950    2             A3           NaN   \n",
      "\n",
      "   jockey_recent_2_course_type  jockey_index  jockey_place_rate  running_style  \n",
      "0                          2.0           0.4           0.322767              2  \n",
      "1                          2.0           0.4           0.322767              2  \n",
      "2                          2.0           0.4           0.322767              2  \n",
      "3                          2.0           0.4           0.322767              2  \n",
      "4                          2.0           0.4           0.322767              2  \n",
      "5                          2.0           0.4           0.322767              2  \n",
      "6                          1.0           0.2           0.104651              3  \n",
      "7                          2.0           0.5           0.172840              1  \n",
      "8                          2.0           0.1           0.097222              2  \n",
      "9                          2.0           0.1           0.097222              2  \n",
      "\n",
      "[DEBUG] 予測結果にrank列が含まれているか: True\n",
      "[DEBUG] 予測結果のrank列の有効値数: 288,988件 / 291,434件\n",
      "[DEBUG] rank列のサンプル値: [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 15.0, 4.0, 8.0, 8.0]\n",
      "\n",
      "============================================================\n",
      "モデル評価（オッズなし）:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] 1着的中率評価: 総レース数=1990, rank==1のレース数=0, 馬番列なしレース数=1990\n",
      "[DEBUG] サンプルレース(20240601_08_04_1_01)のrank値: [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 15.0, 4.0, 8.0, 8.0]\n",
      "[DEBUG] rank==1.0の行数: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "モデル評価結果\n",
      "============================================================\n",
      "\n",
      "NDCG（Normalized Discounted Cumulative Gain）:\n",
      "  NDCG@1: 0.9290\n",
      "  NDCG@2: 0.9292\n",
      "  NDCG@3: 0.9290\n",
      "\n",
      "1着的中率: 0.00% (0/0レース)\n",
      "3着以内的中率: 0.00% (0/0レース)\n",
      "\n",
      "平均順位誤差: 77.56位\n"
     ]
    }
   ],
   "source": [
    "# 検証データで予測を実行\n",
    "print(\"検証データで予測を実行します...\")\n",
    "\n",
    "# デバッグ: val_dfにrank列が含まれているか確認\n",
    "print(f\"[DEBUG] val_dfにrank列が含まれているか: {'rank' in val_df.columns}\")\n",
    "if 'rank' in val_df.columns:\n",
    "    rank_count = val_df['rank'].notna().sum()\n",
    "    print(f\"[DEBUG] val_dfのrank列の有効値数: {rank_count:,}件 / {len(val_df):,}件\")\n",
    "    print(f\"[DEBUG] val_dfのインデックス名: {val_df.index.name}\")\n",
    "    print(f\"[DEBUG] val_dfのカラム数: {len(val_df.columns)}\")\n",
    "else:\n",
    "    print(\"[WARNING] val_dfにrank列が含まれていません。評価が正しく実行されない可能性があります。\")\n",
    "\n",
    "val_predictions_with_rank = RankPredictor.predict(model, val_df, rank_predictor.features)\n",
    "\n",
    "print(f\"予測完了: {len(val_predictions_with_rank)}件\")\n",
    "print(f\"\\n予測結果のサンプル:\")\n",
    "print(val_predictions_with_rank.head(10))\n",
    "\n",
    "# デバッグ: 予測結果にrank列が含まれているか確認\n",
    "print(f\"\\n[DEBUG] 予測結果にrank列が含まれているか: {'rank' in val_predictions_with_rank.columns}\")\n",
    "if 'rank' in val_predictions_with_rank.columns:\n",
    "    rank_count = val_predictions_with_rank['rank'].notna().sum()\n",
    "    print(f\"[DEBUG] 予測結果のrank列の有効値数: {rank_count:,}件 / {len(val_predictions_with_rank):,}件\")\n",
    "    if rank_count > 0:\n",
    "        print(f\"[DEBUG] rank列のサンプル値: {val_predictions_with_rank['rank'].dropna().head(10).tolist()}\")\n",
    "\n",
    "# 基本的な評価を実行（オッズなし）\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"モデル評価（オッズなし）:\")\n",
    "print(\"=\" * 60)\n",
    "RankPredictor.print_evaluation(val_predictions_with_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "オッズデータを取得しました: 21カラム\n",
      "オッズカラム: ['基準オッズ', '基準複勝オッズ', '基準複勝人気順位', '枠確定馬体重', '枠確定馬体重増減', '騎手期待単勝率', '単勝', '複勝', '単勝_SED', 'rank']...\n"
     ]
    }
   ],
   "source": [
    "# オッズデータの取得（original_dfから）\n",
    "# original_dfには評価用カラム（オッズ、着順など）が含まれている\n",
    "evaluation_keywords = [\"オッズ\", \"着順\", \"rank\", \"単勝\", \"複勝\", \"確定\"]\n",
    "odds_cols = [col for col in original_df.columns if any(keyword in col for keyword in evaluation_keywords)]\n",
    "\n",
    "if odds_cols:\n",
    "    odds_df = original_df[odds_cols].copy()\n",
    "    print(f\"オッズデータを取得しました: {len(odds_cols)}カラム\")\n",
    "    print(f\"オッズカラム: {odds_cols[:10]}...\")  # 最初の10カラムを表示\n",
    "else:\n",
    "    print(\"\\n警告: オッズデータが見つかりませんでした。\")\n",
    "    odds_df = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量重要度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量重要度（上位20）:\n",
      "                      feature    importance\n",
      "10          horse_weight_diff  39332.483607\n",
      "6                    horse_id  24447.160331\n",
      "4           distance_aptitude  10279.393658\n",
      "49            prev_1_race_num   6753.476766\n",
      "58            prev_2_race_num   3893.581853\n",
      "11             horse_win_rate   2533.252210\n",
      "105                trainer_id   1836.332117\n",
      "14                  jockey_id   1244.563377\n",
      "67            prev_3_race_num   1212.215018\n",
      "22   jockey_recent_1_race_num   1194.484939\n",
      "104          trainer_avg_rank    934.266791\n",
      "87                prev_5_time    898.552408\n",
      "36   jockey_recent_3_race_num    825.450601\n",
      "29   jockey_recent_2_race_num    687.527588\n",
      "43         prev_1_course_type    356.821267\n",
      "76            prev_4_race_num    349.922218\n",
      "5              horse_avg_rank    294.487492\n",
      "50                prev_1_rank    290.522604\n",
      "8            horse_race_count    265.021181\n",
      "102                      time    258.518022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 37325 (\\N{CJK UNIFIED IDEOGRAPH-91CD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 35201 (\\N{CJK UNIFIED IDEOGRAPH-8981}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 24500 (\\N{CJK UNIFIED IDEOGRAPH-5FB4}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 65288 (\\N{FULLWIDTH LEFT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 19978 (\\N{CJK UNIFIED IDEOGRAPH-4E0A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/mm/c2gn__y56p58dssh1byn5wbh0000gn/T/ipykernel_45658/1131581493.py:18: UserWarning: Glyph 65289 (\\N{FULLWIDTH RIGHT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 29305 (\\N{CJK UNIFIED IDEOGRAPH-7279}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24500 (\\N{CJK UNIFIED IDEOGRAPH-5FB4}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 37325 (\\N{CJK UNIFIED IDEOGRAPH-91CD}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 35201 (\\N{CJK UNIFIED IDEOGRAPH-8981}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 65288 (\\N{FULLWIDTH LEFT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 19978 (\\N{CJK UNIFIED IDEOGRAPH-4E0A}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20301 (\\N{CJK UNIFIED IDEOGRAPH-4F4D}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/soichiro/Dev/umayomi/apps/prediction/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 65289 (\\N{FULLWIDTH RIGHT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 特徴量重要度を取得\n",
    "importance = model.feature_importance(importance_type='gain')\n",
    "feature_names = [f for f in rank_predictor.features.encoded_feature_names if f in val_df.columns]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names[:len(importance)],\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"特徴量重要度（上位20）:\")\n",
    "print(importance_df.head(20))\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df.head(20), y='feature', x='importance')\n",
    "plt.title('特徴量重要度（上位20）')\n",
    "plt.xlabel('重要度')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
