# データ処理フロー

## 概要

`data_processer`は、JRDBのNPZファイルから学習用データを生成するまでの全処理を、シンプルで明確なステップで実行します。

## 全体フロー

```
NPZファイル → 結合 → 特徴量追加 → 変換 → 分割 → 学習用データ
```

## 詳細フロー

### ステップ1: データ読み込みと結合

**処理**: `DataLoader.load()` → `DataCombiner.combine()`

1. **NPZファイル読み込み**
   - 各データタイプ（KYI, BAC, SED, UKC, TYB）を個別に読み込み
   - `data_dict[data_type] = DataFrame` の形式で保持

2. **データ結合**
   - `KYI`をベースに、`full_info_schema.json`の`joinKeys`定義に基づいて結合
   - SEDデータの`着順`を保持（`rank`は後で追加）
   - `着順 > 0`のレコードのみ残す（取消・除外を除外）

**出力**: `raw_df`（日本語キー、全データタイプ結合済み）

### ステップ2: 特徴量追加

**処理**: `FeatureExtractor.extract_previous_races()` → `FeatureExtractor.extract_statistics()`

3. **前走データ抽出**
   - SEDデータから各馬の前走データ（最大5走）を抽出
   - `前走1距離`、`前走1着順`、`前走1タイム`などのカラムを追加

4. **統計特徴量計算**
   - **馬の統計量**: `馬勝率`、`馬連対率`、`馬平均着順`、`馬出走回数`
   - **騎手の統計量**: `騎手勝率`、`騎手連対率`、`騎手平均着順`、`騎手出走回数`
   - **騎手の直近レース**: `騎手直近1着順`、`騎手直近1タイム`など（最大3レース）
   - **調教師の統計量**: `調教師勝率`、`調教師連対率`、`調教師平均着順`、`調教師出走回数`
   - ⚠️ **未来情報除外**: 各レースの`start_datetime`より前のデータのみ使用

**出力**: `featured_df`（日本語キー、統計特徴量・前走データ追加済み）

### ステップ3: データ変換

**処理**: `DataConverter.convert()` → `DataConverter.optimize()`

5. **キー変換と数値化**
   - `full_info_schema.json`に基づいて日本語キー→英語キー（`feature_name`）に変換
   - 例: `馬勝率` → `horse_win_rate`、`前走1距離` → `prev_1_distance`
   - `着順` → `rank`、`タイム` → `time`に変換
   - カテゴリカル変数をラベルエンコーディング（`e_*`プレフィックス付き）

6. **データ型最適化**
   - float64→float32、int64→int32に変換してメモリ使用量を削減
   - object型カラムをクリーンアップ

**出力**: `converted_df`（英語キー、数値化・最適化済み）

### ステップ4: 時系列分割とカラム選択（`split_date`指定時）

**処理**: `DataSplitter.split()` → `ColumnSelector.select_training()` → `ColumnSelector.select_evaluation()`

7. **時系列分割**
   - `split_date`以前を学習データ、以降を検証データに分割
   - `race_key`をインデックスに設定し、`start_datetime`でソート済み

8. **学習用カラム選択**
   - `full_info_schema.json`の`use_for_training=true`のカラムを選択
   - `training_schema.json`の`target_variable`（`rank`）も含める
   - 英語キー（`feature_name`）で返す

9. **評価用データ作成**
   - `full_info_schema.json`の全カラム（日本語キー）を保持
   - 評価時に必要な情報（`race_key`、`着順`、`馬番`、`タイム`など）がすべて含まれる

**出力**: 
- `train_df`: 学習用カラムのみ（`rank`含む、英語キー）
- `test_df`: 学習用カラムのみ（`rank`含む、英語キー）
- `eval_df`: 全カラム（評価用、日本語キー）

## 重要なポイント

### 1. データの流れ

```
日本語キー（結合・特徴量追加）
  ↓
英語キー（数値変換）
  ↓
学習用カラム（カラムフィルタリング）
```

### 2. 未来情報の除外

- 統計特徴量計算では、各レースの`start_datetime`より**前**のデータのみを使用
- `np.searchsorted(..., side='left')`を使用して未来情報を完全に除外
- 時系列で累積統計量を計算（`groupby().cumsum()`）

### 3. スキーマの役割

- **`full_info_schema.json`**: 全結合データの定義（日本語キー + 英語キー + 学習用フラグ）
- **`training_schema.json`**: 学習用データの定義（ターゲット変数含む）
- **`combined_schema.json`**: 結合キー定義（`joinKeys`）

### 4. キャッシュ戦略

- `raw_df`（結合済み、日本語キー）をキャッシュ
- `converted_df`（変換済み、英語キー）をキャッシュ
- キャッシュはParquet形式で保存（メタデータにカラム名エイリアスを保存）

## あるべき状態

1. **明確な責務分離**
   - 各ステップは単一の責務を持つ
   - データの流れが明確で、デバッグが容易

2. **スキーマ駆動**
   - すべての処理はスキーマ定義に基づく
   - スキーマ変更に柔軟に対応

3. **未来情報の完全除外**
   - 統計特徴量計算時に未来情報を完全に除外
   - 時系列整合性を保証

4. **シンプルな実装**
   - 不要な分岐や複雑な条件分岐を避ける
   - コードが読みやすく、保守しやすい

