# キャッシュフォーマット比較

## 現在の形式: NPZ + JSON

### メリット
- NumPy標準形式で互換性が高い
- 圧縮サポート（`np.savez_compressed`）

### デメリット
- ❌ インデックスを手動で保存・復元する必要がある
- ❌ 型情報が失われる可能性がある（オブジェクト型は文字列に変換）
- ❌ 複雑な実装（インデックス名の扱いが面倒）

## 代替フォーマット

### 1. Parquet（推奨）⭐

**特徴:**
- 列指向ストレージ形式
- Apache Arrowベース
- 圧縮効率が高い（Snappy、Gzip、Brotli）
- 型情報を完全に保持
- インデックスを自動的に保存・復元

**メリット:**
- ✅ `index=True`でインデックスを自動保存・復元
- ✅ 型情報が完全に保持される（カテゴリカル型、日時型など）
- ✅ 圧縮効率が高い（ファイルサイズが小さい）
- ✅ 読み書きが高速（列指向）
- ✅ 必要なカラムのみ読み込み可能（メモリ効率）
- ✅ 多くのツールでサポート（Pandas、Spark、DuckDBなど）

**デメリット:**
- ⚠️ `pyarrow`または`fastparquet`ライブラリが必要
- ⚠️ 既存キャッシュとの互換性がない（移行が必要）

**実装例:**
```python
# 保存
df.to_parquet('data.parquet', index=True, compression='snappy')

# 読み込み
df = pd.read_parquet('data.parquet')
# インデックスは自動的に復元される
```

### 2. Feather

**特徴:**
- Apache Arrowベース
- 読み書きが非常に高速
- 型情報を完全に保持
- インデックスを自動的に保存・復元

**メリット:**
- ✅ 読み書きが最も高速
- ✅ インデックスを自動保存・復元
- ✅ 型情報が完全に保持される

**デメリット:**
- ⚠️ `pyarrow`ライブラリが必要
- ⚠️ 圧縮が弱い（ファイルサイズが大きい）
- ⚠️ 互換性が低い（Python専用）

**実装例:**
```python
# 保存
df.to_feather('data.feather')

# 読み込み
df = pd.read_feather('data.feather')
```

### 3. Pickle

**特徴:**
- Python専用のシリアライゼーション形式
- 完全な情報保持（インデックス、型、メタデータすべて）

**メリット:**
- ✅ 完全な情報保持（何も失わない）
- ✅ インデックスを自動保存・復元
- ✅ 標準ライブラリで利用可能

**デメリット:**
- ⚠️ Python専用（他のツールで読み込めない）
- ⚠️ セキュリティリスク（任意のコード実行の可能性）
- ⚠️ バージョン依存性（Pandasのバージョンが異なると読み込めない可能性）

**実装例:**
```python
# 保存
df.to_pickle('data.pkl')

# 読み込み
df = pd.read_pickle('data.pkl')
```

### 4. HDF5

**特徴:**
- 階層構造を持つバイナリ形式
- 非常に高い圧縮率
- インデックス対応

**メリット:**
- ✅ 高い圧縮率
- ✅ 階層構造（複数のDataFrameを1ファイルに保存可能）
- ✅ インデックス対応

**デメリット:**
- ⚠️ `PyTables`または`h5py`ライブラリが必要
- ⚠️ 実装が複雑
- ⚠️ 読み書きがやや遅い

## 推奨: Parquet形式

**理由:**
1. インデックスを自動的に保存・復元できる（手動実装が不要）
2. 型情報が完全に保持される
3. 圧縮効率が高い（ファイルサイズが小さい）
4. 読み書きが高速
5. 多くのツールでサポートされている

**移行時の注意点:**
- 既存のNPZキャッシュは削除するか、移行スクリプトを作成
- `pyarrow`ライブラリをインストールする必要がある

